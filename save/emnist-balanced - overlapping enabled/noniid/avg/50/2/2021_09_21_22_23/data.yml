avg_train_accuracy: 0.933
avg_train_loss: 0.001
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.06776595744680851
- 0.4621276595744681
- 0.46643617021276595
- 0.5956914893617021
- 0.5956914893617021
- 0.5956914893617021
- 0.6942021276595745
- 0.6942021276595745
- 0.6942021276595745
- 0.6942021276595745
- 0.6942021276595745
- 0.7226063829787234
- 0.7226063829787234
- 0.7226063829787234
- 0.7226063829787234
- 0.7226063829787234
- 0.7226063829787234
- 0.7226063829787234
- 0.7459574468085106
- 0.7459574468085106
- 0.7459574468085106
- 0.7459574468085106
- 0.7459574468085106
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7499468085106383
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
- 0.7547340425531915
test_loss_list:
- 552.7148008346558
- 319.75096130371094
- 257.44443237781525
- 203.0138885974884
- 203.0138885974884
- 203.0138885974884
- 149.10597330331802
- 149.10597330331802
- 149.10597330331802
- 149.10597330331802
- 149.10597330331802
- 122.79048371315002
- 122.79048371315002
- 122.79048371315002
- 122.79048371315002
- 122.79048371315002
- 122.79048371315002
- 122.79048371315002
- 116.65207862854004
- 116.65207862854004
- 116.65207862854004
- 116.65207862854004
- 116.65207862854004
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 109.61695611476898
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
- 110.09025371074677
train_accuracy:
- 0.875
- 0.442
- 0.512
- 0.596
- 0.617
- 0.579
- 0.746
- 0.725
- 0.992
- 0.679
- 0.938
- 0.733
- 0.929
- 0.983
- 0.754
- 0.312
- 0.921
- 0.742
- 0.696
- 0.967
- 0.629
- 0.992
- 0.925
- 0.779
- 0.75
- 0.658
- 0.933
- 0.943
- 0.987
- 0.617
- 0.704
- 0.979
- 0.888
- 0.617
- 0.971
- 0.683
- 0.663
- 0.954
- 0.625
- 0.792
- 0.683
- 0.904
- 0.975
- 1.0
- 0.987
- 0.788
- 0.958
- 0.767
- 0.729
- 0.933
train_loss:
- 0.933
- 2.01
- 1.023
- 1.429
- 0.877
- 0.461
- 1.592
- 1.131
- 0.747
- 0.738
- 0.711
- 1.378
- 0.387
- 0.729
- 0.982
- 0.088
- 0.7
- 0.702
- 0.963
- 0.933
- 0.371
- 0.967
- 0.082
- 1.192
- 0.378
- 0.91
- 0.315
- 0.609
- 0.365
- 0.337
- 0.631
- 0.619
- 0.347
- 0.353
- 0.348
- 0.365
- 0.62
- 0.332
- 0.311
- 0.893
- 0.329
- 0.33
- 0.6
- 0.324
- 0.314
- 0.604
- 0.592
- 0.833
- 0.599
- 0.063
unequal: 0
verbose: 1
