avg_train_accuracy: 0.9
avg_train_loss: 0.003
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.038670212765957446
- 0.038670212765957446
- 0.038670212765957446
- 0.038670212765957446
- 0.03930851063829787
- 0.06909574468085107
- 0.06909574468085107
- 0.06968085106382979
- 0.214468085106383
- 0.214468085106383
- 0.3841489361702128
- 0.3841489361702128
- 0.3841489361702128
- 0.5665425531914894
- 0.5665425531914894
- 0.5868617021276595
- 0.5868617021276595
- 0.5868617021276595
- 0.6644148936170213
- 0.6644148936170213
- 0.6644148936170213
- 0.6644148936170213
- 0.6644148936170213
- 0.6644148936170213
- 0.6644148936170213
- 0.6644148936170213
- 0.6644148936170213
- 0.6765425531914894
- 0.6765425531914894
- 0.6765425531914894
- 0.6765425531914894
- 0.6765425531914894
- 0.6765425531914894
- 0.6765425531914894
- 0.6765425531914894
- 0.6765425531914894
- 0.708031914893617
- 0.708031914893617
- 0.708031914893617
- 0.708031914893617
- 0.708031914893617
- 0.708031914893617
- 0.708031914893617
- 0.708031914893617
- 0.708031914893617
- 0.708031914893617
- 0.7102659574468085
- 0.7489893617021277
- 0.7489893617021277
- 0.7489893617021277
test_loss_list:
- 1124.47261428833
- 1124.47261428833
- 1124.47261428833
- 1124.47261428833
- 1463.024419784546
- 586.9282281398773
- 586.9282281398773
- 711.1915574073792
- 428.5137195587158
- 428.5137195587158
- 302.91890799999237
- 302.91890799999237
- 302.91890799999237
- 197.97671103477478
- 197.97671103477478
- 199.39281034469604
- 199.39281034469604
- 199.39281034469604
- 156.17954522371292
- 156.17954522371292
- 156.17954522371292
- 156.17954522371292
- 156.17954522371292
- 156.17954522371292
- 156.17954522371292
- 156.17954522371292
- 156.17954522371292
- 148.7818421125412
- 148.7818421125412
- 148.7818421125412
- 148.7818421125412
- 148.7818421125412
- 148.7818421125412
- 148.7818421125412
- 148.7818421125412
- 148.7818421125412
- 130.26809060573578
- 130.26809060573578
- 130.26809060573578
- 130.26809060573578
- 130.26809060573578
- 130.26809060573578
- 130.26809060573578
- 130.26809060573578
- 130.26809060573578
- 130.26809060573578
- 138.5862391591072
- 113.7637225985527
- 113.7637225985527
- 113.7637225985527
train_accuracy:
- 0.95
- 0.317
- 0.0
- 0.029
- 0.154
- 0.958
- 0.971
- 0.929
- 1.0
- 0.188
- 0.992
- 0.917
- 0.858
- 0.954
- 0.967
- 0.554
- 0.875
- 0.896
- 0.642
- 0.967
- 0.562
- 0.987
- 0.688
- 0.425
- 1.0
- 0.704
- 0.542
- 0.987
- 0.921
- 0.938
- 0.946
- 0.942
- 0.983
- 0.979
- 0.954
- 0.996
- 0.692
- 0.917
- 0.637
- 0.983
- 0.962
- 0.979
- 0.971
- 0.696
- 0.929
- 0.925
- 0.95
- 0.962
- 0.979
- 0.9
train_loss:
- 0.037
- 0.016
- 0.017
- 1.693
- 0.014
- 0.63
- 0.012
- 0.58
- 0.535
- 0.509
- 0.488
- 0.008
- 0.01
- 0.929
- 0.01
- 0.839
- 0.012
- 0.011
- 1.214
- 0.389
- 0.407
- 0.388
- 0.377
- 0.356
- 0.773
- 0.724
- 0.349
- 0.721
- 0.015
- 0.344
- 0.012
- 0.017
- 0.361
- 0.36
- 0.689
- 0.014
- 0.664
- 0.018
- 0.351
- 0.335
- 0.349
- 0.012
- 0.329
- 0.649
- 0.349
- 0.011
- 0.66
- 0.938
- 0.322
- 0.316
unequal: 0
verbose: 1
