avg_train_accuracy: 0.833
avg_train_loss: 0.011
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.039521276595744684
- 0.4799468085106383
- 0.4799468085106383
- 0.555
- 0.555
- 0.6789893617021276
- 0.7018617021276595
- 0.7018617021276595
- 0.7018617021276595
- 0.7018617021276595
- 0.7018617021276595
- 0.7018617021276595
- 0.7018617021276595
- 0.7056914893617021
- 0.7056914893617021
- 0.7056914893617021
- 0.7156382978723405
- 0.7415957446808511
- 0.7415957446808511
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7558510638297873
- 0.7701595744680851
- 0.7701595744680851
- 0.7701595744680851
- 0.7701595744680851
- 0.7770212765957447
test_loss_list:
- 539.0548410415649
- 267.1093884706497
- 267.1093884706497
- 205.82254576683044
- 205.82254576683044
- 159.95933520793915
- 142.15534663200378
- 142.15534663200378
- 142.15534663200378
- 142.15534663200378
- 142.15534663200378
- 142.15534663200378
- 142.15534663200378
- 133.1536871790886
- 133.1536871790886
- 133.1536871790886
- 136.66501080989838
- 115.64999669790268
- 115.64999669790268
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 112.37980967760086
- 99.8040728867054
- 99.8040728867054
- 99.8040728867054
- 99.8040728867054
- 99.33511224389076
train_accuracy:
- 0.987
- 0.896
- 0.483
- 0.579
- 0.933
- 0.712
- 0.667
- 0.983
- 0.958
- 0.967
- 0.975
- 0.729
- 0.962
- 0.721
- 0.979
- 0.971
- 0.754
- 0.754
- 0.733
- 0.8
- 0.971
- 0.75
- 0.975
- 0.996
- 0.725
- 0.775
- 0.996
- 0.792
- 0.962
- 0.792
- 0.679
- 0.95
- 0.971
- 0.775
- 0.712
- 1.0
- 0.975
- 0.971
- 0.696
- 0.758
- 0.825
- 0.987
- 0.975
- 0.992
- 1.0
- 0.821
- 0.971
- 0.987
- 0.979
- 0.833
train_loss:
- 1.663
- 1.845
- 1.001
- 0.945
- 0.441
- 1.682
- 1.573
- 1.111
- 0.732
- 0.017
- 0.364
- 0.726
- 0.351
- 1.028
- 0.369
- 0.662
- 0.658
- 1.302
- 0.648
- 1.252
- 0.637
- 0.919
- 0.62
- 0.616
- 0.315
- 0.917
- 0.622
- 0.889
- 0.625
- 0.899
- 0.59
- 0.584
- 0.289
- 0.857
- 0.301
- 0.282
- 0.554
- 0.561
- 0.277
- 0.576
- 0.852
- 0.275
- 0.293
- 0.296
- 0.275
- 1.14
- 0.29
- 0.555
- 0.302
- 1.086
unequal: 0
verbose: 1
