avg_train_accuracy: 0.896
avg_train_loss: 0.0
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.04952127659574468
- 0.46787234042553194
- 0.5581382978723404
- 0.5894148936170213
- 0.5894148936170213
- 0.6488297872340425
- 0.6643617021276595
- 0.6643617021276595
- 0.6864361702127659
- 0.6864361702127659
- 0.7030851063829787
- 0.7030851063829787
- 0.7030851063829787
- 0.7132446808510639
- 0.7132446808510639
- 0.7132446808510639
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7403191489361702
- 0.7473404255319149
- 0.7473404255319149
- 0.7473404255319149
- 0.7473404255319149
- 0.7473404255319149
- 0.7473404255319149
- 0.7501595744680851
- 0.7501595744680851
- 0.7501595744680851
- 0.7638829787234043
- 0.7638829787234043
- 0.7638829787234043
- 0.7638829787234043
- 0.7638829787234043
- 0.7638829787234043
- 0.7638829787234043
- 0.7638829787234043
- 0.766436170212766
- 0.766436170212766
- 0.766436170212766
- 0.766436170212766
- 0.766436170212766
- 0.766436170212766
test_loss_list:
- 511.87093448638916
- 271.9193218946457
- 216.65968108177185
- 189.85162127017975
- 189.85162127017975
- 166.6353456377983
- 154.90154719352722
- 154.90154719352722
- 146.46540021896362
- 146.46540021896362
- 131.51184660196304
- 131.51184660196304
- 131.51184660196304
- 126.82142347097397
- 126.82142347097397
- 126.82142347097397
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 119.56712555885315
- 114.72109323740005
- 114.72109323740005
- 114.72109323740005
- 114.72109323740005
- 114.72109323740005
- 114.72109323740005
- 112.97222149372101
- 112.97222149372101
- 112.97222149372101
- 101.24464982748032
- 101.24464982748032
- 101.24464982748032
- 101.24464982748032
- 101.24464982748032
- 101.24464982748032
- 101.24464982748032
- 101.24464982748032
- 99.72160151600838
- 99.72160151600838
- 99.72160151600838
- 99.72160151600838
- 99.72160151600838
- 99.72160151600838
train_accuracy:
- 0.042
- 0.542
- 0.571
- 0.667
- 0.896
- 0.967
- 0.683
- 0.854
- 0.975
- 0.958
- 0.75
- 0.679
- 0.983
- 0.946
- 0.742
- 0.958
- 0.792
- 0.692
- 0.738
- 0.958
- 0.967
- 0.996
- 0.971
- 0.479
- 0.971
- 0.975
- 0.954
- 0.767
- 0.992
- 0.992
- 0.779
- 0.971
- 0.75
- 0.792
- 0.767
- 0.683
- 0.825
- 0.804
- 0.95
- 0.738
- 0.767
- 0.958
- 0.879
- 0.987
- 0.804
- 0.983
- 0.962
- 0.987
- 0.971
- 0.896
train_loss:
- 1.605
- 1.789
- 1.468
- 1.311
- 0.015
- 1.228
- 1.19
- 0.389
- 1.103
- 0.723
- 1.042
- 1.014
- 0.016
- 0.997
- 0.993
- 0.321
- 1.31
- 0.323
- 0.933
- 0.631
- 0.619
- 0.923
- 0.595
- 0.614
- 0.915
- 0.608
- 0.299
- 0.883
- 0.301
- 0.592
- 0.875
- 0.018
- 0.853
- 0.579
- 0.307
- 0.557
- 1.106
- 1.102
- 0.287
- 0.554
- 0.85
- 0.581
- 0.015
- 0.548
- 1.086
- 0.261
- 0.545
- 0.554
- 0.019
- 0.018
unequal: 0
verbose: 1
