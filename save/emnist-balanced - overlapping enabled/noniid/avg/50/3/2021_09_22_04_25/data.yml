avg_train_accuracy: 0.775
avg_train_loss: 0.009
avg_type: avg
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1376063829787234
- 0.1376063829787234
- 0.2179255319148936
- 0.561063829787234
- 0.561063829787234
- 0.5646808510638298
- 0.5646808510638298
- 0.6668085106382978
- 0.6668085106382978
- 0.693404255319149
- 0.693404255319149
- 0.693404255319149
- 0.7101063829787234
- 0.7197340425531915
- 0.7197340425531915
- 0.7197340425531915
- 0.7197340425531915
- 0.7351063829787234
- 0.7351063829787234
- 0.7351063829787234
- 0.7351063829787234
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7607978723404255
- 0.7695212765957447
- 0.7695212765957447
- 0.7695212765957447
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
- 0.7764893617021277
test_loss_list:
- 493.4942247867584
- 493.4942247867584
- 407.8312797546387
- 235.52980661392212
- 235.52980661392212
- 203.33141541481018
- 203.33141541481018
- 162.03603714704514
- 162.03603714704514
- 144.25375217199326
- 144.25375217199326
- 144.25375217199326
- 130.4575035572052
- 130.1224474310875
- 130.1224474310875
- 130.1224474310875
- 130.1224474310875
- 120.19242882728577
- 120.19242882728577
- 120.19242882728577
- 120.19242882728577
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 107.80869770050049
- 103.53970888257027
- 103.53970888257027
- 103.53970888257027
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
- 99.80023321509361
train_accuracy:
- 0.888
- 0.979
- 0.162
- 0.571
- 0.733
- 0.896
- 0.562
- 0.733
- 0.983
- 0.646
- 0.892
- 0.717
- 0.746
- 0.721
- 0.579
- 0.938
- 0.704
- 0.775
- 0.771
- 0.742
- 0.871
- 0.783
- 0.754
- 0.708
- 0.675
- 0.733
- 0.871
- 0.783
- 0.967
- 0.958
- 0.758
- 0.742
- 0.767
- 0.779
- 0.783
- 0.862
- 0.629
- 0.867
- 0.646
- 0.721
- 0.971
- 0.971
- 0.996
- 0.992
- 0.888
- 0.633
- 0.75
- 0.958
- 0.958
- 0.775
train_loss:
- 1.81
- 0.221
- 0.702
- 1.619
- 0.94
- 0.965
- 0.863
- 1.195
- 0.48
- 1.174
- 1.136
- 0.773
- 1.057
- 1.062
- 0.397
- 0.745
- 0.697
- 1.014
- 0.972
- 0.986
- 0.692
- 1.203
- 0.689
- 0.657
- 0.415
- 0.941
- 0.141
- 0.9
- 0.355
- 0.644
- 0.625
- 0.663
- 1.194
- 0.902
- 0.648
- 1.129
- 0.376
- 0.368
- 0.378
- 0.656
- 0.645
- 0.358
- 0.098
- 0.656
- 0.113
- 0.396
- 0.875
- 0.368
- 0.621
- 0.852
unequal: 0
verbose: 1
