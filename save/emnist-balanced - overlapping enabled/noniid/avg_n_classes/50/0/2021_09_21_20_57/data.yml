avg_train_accuracy: 0.0
avg_train_loss: 0.0
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 0
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.021329787234042552
- 0.021329787234042552
- 0.02170212765957447
- 0.023936170212765957
- 0.023936170212765957
- 0.023936170212765957
- 0.03021276595744681
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.0323936170212766
- 0.03707446808510638
- 0.03707446808510638
- 0.03707446808510638
- 0.03888297872340426
- 0.03888297872340426
- 0.03888297872340426
test_loss_list:
- 1584.6644439697266
- 1584.6644439697266
- 1943.0587530136108
- 1584.9161214828491
- 1584.9161214828491
- 1584.9161214828491
- 1283.477153301239
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1438.1012001037598
- 1105.4184656143188
- 1105.4184656143188
- 1105.4184656143188
- 1069.7481780052185
- 1069.7481780052185
- 1069.7481780052185
train_accuracy:
- 0.004
- 0.0
- 0.0
- 0.129
- 0.0
- 0.0
- 0.854
- 0.983
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 1.0
- 0.0
- 0.0
- 1.0
- 0.0
- 0.0
- 1.0
- 1.0
- 0.363
- 0.146
- 0.0
- 0.0
- 0.0
- 0.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 0.471
- 0.0
- 0.0
- 0.0
- 0.996
- 1.0
- 0.104
- 0.996
- 0.0
- 1.0
- 0.0
- 1.0
- 0.917
- 0.0
- 0.0
- 0.008
- 0.0
- 0.0
train_loss:
- 0.029
- 0.015
- 0.013
- 0.014
- 0.021
- 0.016
- 0.018
- 0.013
- 0.015
- 0.019
- 0.012
- 0.016
- 0.015
- 0.017
- 0.01
- 0.015
- 0.009
- 0.015
- 0.007
- 0.012
- 0.016
- 0.011
- 0.012
- 0.011
- 0.014
- 0.012
- 0.013
- 0.016
- 0.012
- 0.012
- 0.014
- 0.009
- 0.014
- 0.012
- 0.013
- 0.012
- 0.011
- 0.011
- 0.011
- 0.014
- 0.011
- 0.015
- 0.01
- 0.011
- 0.014
- 0.011
- 0.009
- 0.013
- 0.01
- 0.008
unequal: 0
verbose: 1
