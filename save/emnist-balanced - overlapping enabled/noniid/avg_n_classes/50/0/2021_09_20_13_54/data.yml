avg_train_accuracy: 0.0
avg_train_loss: 0.0
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 0
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.032872340425531915
- 0.034148936170212765
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
- 0.04952127659574468
test_loss_list:
- 1645.8351373672485
- 1411.8326625823975
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
- 1494.5216827392578
train_accuracy:
- 0.496
- 0.629
- 0.521
- 0.0
- 0.0
- 1.0
- 0.0
- 0.125
- 0.0
- 0.0
- 0.0
- 0.0
- 0.0
- 1.0
- 1.0
- 0.0
- 0.0
- 0.0
- 0.0
- 1.0
- 0.0
- 0.0
- 0.0
- 1.0
- 0.0
- 0.0
- 0.0
- 1.0
- 0.0
- 1.0
- 0.95
- 0.0
- 0.0
- 0.0
- 0.0
- 0.608
- 1.0
- 0.967
- 0.0
- 0.0
- 0.0
- 0.125
- 0.0
- 0.971
- 0.0
- 0.0
- 1.0
- 1.0
- 0.383
- 0.0
train_loss:
- 0.027
- 0.018
- 0.016
- 0.021
- 0.011
- 0.014
- 0.022
- 0.017
- 0.014
- 0.016
- 0.022
- 0.013
- 0.018
- 0.019
- 0.016
- 0.017
- 0.015
- 0.013
- 0.012
- 0.015
- 0.014
- 0.017
- 0.013
- 0.015
- 0.012
- 0.012
- 0.012
- 0.016
- 0.012
- 0.011
- 0.011
- 0.013
- 0.015
- 0.011
- 0.014
- 0.01
- 0.015
- 0.013
- 0.012
- 0.013
- 0.01
- 0.012
- 0.013
- 0.01
- 0.01
- 0.012
- 0.012
- 0.01
- 0.015
- 0.012
unequal: 0
verbose: 1
