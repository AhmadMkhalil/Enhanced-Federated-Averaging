avg_train_accuracy: 0.308
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.4152659574468085
- 0.5709042553191489
- 0.6386702127659575
- 0.676595744680851
- 0.676595744680851
- 0.7060106382978724
- 0.7134574468085106
- 0.7241489361702128
- 0.7241489361702128
- 0.746968085106383
- 0.746968085106383
- 0.7486170212765958
- 0.7486170212765958
- 0.7492553191489362
- 0.7492553191489362
- 0.763563829787234
- 0.763563829787234
- 0.763563829787234
- 0.763563829787234
- 0.763563829787234
- 0.763563829787234
- 0.763563829787234
- 0.763563829787234
- 0.7670212765957447
- 0.7670212765957447
- 0.7677127659574469
- 0.7677127659574469
- 0.7741489361702127
- 0.7741489361702127
- 0.7741489361702127
- 0.7741489361702127
- 0.7741489361702127
- 0.7741489361702127
- 0.7741489361702127
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.779468085106383
- 0.7837765957446808
- 0.7837765957446808
- 0.7837765957446808
- 0.7837765957446808
- 0.7837765957446808
test_loss_list:
- 364.8034007549286
- 220.6162621974945
- 183.78108489513397
- 161.24707502126694
- 161.24707502126694
- 139.87137961387634
- 131.80601662397385
- 127.17409199476242
- 127.17409199476242
- 118.2016492486
- 118.2016492486
- 114.9492798447609
- 114.9492798447609
- 110.50268369913101
- 110.50268369913101
- 106.79723709821701
- 106.79723709821701
- 106.79723709821701
- 106.79723709821701
- 106.79723709821701
- 106.79723709821701
- 106.79723709821701
- 106.79723709821701
- 104.02427685260773
- 104.02427685260773
- 103.84017777442932
- 103.84017777442932
- 102.19479167461395
- 102.19479167461395
- 102.19479167461395
- 102.19479167461395
- 102.19479167461395
- 102.19479167461395
- 102.19479167461395
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 97.5609096288681
- 96.02281156182289
- 96.02281156182289
- 96.02281156182289
- 96.02281156182289
- 96.02281156182289
train_accuracy:
- 0.538
- 0.633
- 0.65
- 0.729
- 0.658
- 0.733
- 0.775
- 0.138
- 0.688
- 0.775
- 0.729
- 0.771
- 0.817
- 0.788
- 0.783
- 0.767
- 0.754
- 0.804
- 0.188
- 0.821
- 0.596
- 0.775
- 0.721
- 0.808
- 0.917
- 0.779
- 0.796
- 0.833
- 0.962
- 0.842
- 0.746
- 0.812
- 0.45
- 0.5
- 0.808
- 0.204
- 0.779
- 0.788
- 0.829
- 0.771
- 0.846
- 0.871
- 0.792
- 0.812
- 0.708
- 0.283
- 0.779
- 0.908
- 0.817
- 0.308
train_loss:
- 1.364
- 2.227
- 1.154
- 1.407
- 0.61
- 1.539
- 1.446
- 0.849
- 1.08
- 1.105
- 0.805
- 1.082
- 0.857
- 1.051
- 0.966
- 0.981
- 0.965
- 0.725
- 0.47
- 0.802
- 0.536
- 0.985
- 0.694
- 0.697
- 0.439
- 0.705
- 0.729
- 0.714
- 0.227
- 0.449
- 0.479
- 0.771
- 0.646
- 0.453
- 0.99
- 0.902
- 0.652
- 0.437
- 1.083
- 0.438
- 0.484
- 0.7
- 0.895
- 1.045
- 0.438
- 0.855
- 0.898
- 0.471
- 0.894
- 0.443
unequal: 0
verbose: 1
