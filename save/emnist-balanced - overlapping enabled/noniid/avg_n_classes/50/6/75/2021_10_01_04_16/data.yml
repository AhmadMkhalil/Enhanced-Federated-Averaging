avg_train_accuracy: 0.733
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.15271276595744682
- 0.46702127659574466
- 0.46702127659574466
- 0.46702127659574466
- 0.5950531914893618
- 0.5950531914893618
- 0.5950531914893618
- 0.5950531914893618
- 0.5950531914893618
- 0.6673936170212766
- 0.6673936170212766
- 0.7277659574468085
- 0.7277659574468085
- 0.7277659574468085
- 0.7277659574468085
- 0.7277659574468085
- 0.7277659574468085
- 0.7277659574468085
- 0.737872340425532
- 0.737872340425532
- 0.737872340425532
- 0.737872340425532
- 0.7463829787234042
- 0.7463829787234042
- 0.7471276595744681
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.7587234042553191
- 0.760531914893617
- 0.760531914893617
- 0.760531914893617
- 0.760531914893617
- 0.760531914893617
- 0.7660638297872341
- 0.7660638297872341
- 0.7725531914893617
- 0.7725531914893617
test_loss_list:
- 563.3777360916138
- 309.1228184700012
- 309.1228184700012
- 309.1228184700012
- 192.34828293323517
- 192.34828293323517
- 192.34828293323517
- 192.34828293323517
- 192.34828293323517
- 155.69720721244812
- 155.69720721244812
- 130.69558840990067
- 130.69558840990067
- 130.69558840990067
- 130.69558840990067
- 130.69558840990067
- 130.69558840990067
- 130.69558840990067
- 117.92800098657608
- 117.92800098657608
- 117.92800098657608
- 117.92800098657608
- 115.3583972454071
- 115.3583972454071
- 112.3453471660614
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 106.63229703903198
- 105.72764986753464
- 105.72764986753464
- 105.72764986753464
- 105.72764986753464
- 105.72764986753464
- 103.31964126229286
- 103.31964126229286
- 100.70209294557571
- 100.70209294557571
train_accuracy:
- 0.142
- 0.458
- 0.125
- 0.133
- 0.254
- 0.525
- 0.15
- 0.092
- 0.783
- 0.696
- 0.725
- 0.858
- 0.921
- 0.817
- 0.746
- 0.596
- 0.788
- 0.854
- 0.858
- 0.617
- 0.875
- 0.679
- 0.708
- 0.154
- 0.938
- 0.854
- 0.942
- 0.858
- 0.771
- 0.904
- 0.812
- 0.779
- 0.583
- 0.829
- 0.7
- 0.792
- 0.913
- 0.879
- 0.683
- 0.896
- 0.883
- 0.821
- 0.75
- 0.5
- 0.467
- 0.417
- 0.758
- 0.742
- 0.825
- 0.733
train_loss:
- 0.663
- 1.6
- 0.37
- 0.399
- 0.71
- 0.348
- 0.296
- 0.334
- 0.4
- 0.977
- 0.272
- 1.232
- 0.257
- 0.526
- 0.823
- 0.3
- 0.492
- 0.548
- 0.811
- 0.208
- 0.223
- 0.291
- 0.836
- 0.24
- 0.491
- 0.992
- 0.746
- 0.479
- 0.568
- 0.284
- 0.478
- 0.733
- 0.284
- 0.248
- 0.481
- 0.47
- 0.441
- 0.525
- 0.495
- 0.429
- 0.27
- 0.45
- 0.47
- 0.436
- 0.237
- 0.487
- 0.663
- 0.44
- 0.706
- 0.45
unequal: 0
verbose: 1
