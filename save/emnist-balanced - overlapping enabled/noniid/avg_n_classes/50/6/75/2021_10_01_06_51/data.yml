avg_train_accuracy: 0.792
avg_train_loss: 0.005
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.3881914893617021
- 0.3881914893617021
- 0.5671808510638298
- 0.6372872340425532
- 0.6372872340425532
- 0.6648404255319149
- 0.6909574468085107
- 0.6909574468085107
- 0.7041489361702128
- 0.7110106382978724
- 0.7320212765957447
- 0.7328191489361702
- 0.7328191489361702
- 0.7421808510638298
- 0.7504255319148936
- 0.7504255319148936
- 0.7504255319148936
- 0.7504255319148936
- 0.7504255319148936
- 0.7513829787234042
- 0.7513829787234042
- 0.7513829787234042
- 0.7546276595744681
- 0.7546276595744681
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7660638297872341
- 0.7688297872340426
- 0.7688297872340426
- 0.7688297872340426
- 0.7688297872340426
- 0.7688297872340426
- 0.7688297872340426
- 0.7688297872340426
- 0.7743085106382979
- 0.7743085106382979
- 0.7743085106382979
- 0.7743085106382979
- 0.7743085106382979
- 0.7743085106382979
- 0.7743085106382979
- 0.774468085106383
- 0.774468085106383
test_loss_list:
- 425.1675953865051
- 425.1675953865051
- 222.36566364765167
- 185.18199908733368
- 185.18199908733368
- 158.03204488754272
- 146.36352103948593
- 146.36352103948593
- 138.37958538532257
- 134.1586264371872
- 125.97393304109573
- 124.57988369464874
- 124.57988369464874
- 118.20727747678757
- 113.00218659639359
- 113.00218659639359
- 113.00218659639359
- 113.00218659639359
- 113.00218659639359
- 109.43769705295563
- 109.43769705295563
- 109.43769705295563
- 109.38427585363388
- 109.38427585363388
- 106.03381708264351
- 106.03381708264351
- 106.03381708264351
- 106.03381708264351
- 106.03381708264351
- 106.03381708264351
- 106.03381708264351
- 106.03381708264351
- 106.03381708264351
- 104.94600999355316
- 102.18438243865967
- 102.18438243865967
- 102.18438243865967
- 102.18438243865967
- 102.18438243865967
- 102.18438243865967
- 102.18438243865967
- 102.4791927933693
- 102.4791927933693
- 102.4791927933693
- 102.4791927933693
- 102.4791927933693
- 102.4791927933693
- 102.4791927933693
- 95.70289796590805
- 95.70289796590805
train_accuracy:
- 0.629
- 0.104
- 0.904
- 0.675
- 0.154
- 0.767
- 0.692
- 0.325
- 0.913
- 0.8
- 0.829
- 0.654
- 0.329
- 0.712
- 0.8
- 0.538
- 0.633
- 0.871
- 0.688
- 0.679
- 0.938
- 0.567
- 0.792
- 0.892
- 0.454
- 0.862
- 0.725
- 0.762
- 0.633
- 0.925
- 0.9
- 0.862
- 0.629
- 0.821
- 0.742
- 0.421
- 0.758
- 0.712
- 0.804
- 0.867
- 0.837
- 0.225
- 0.729
- 0.771
- 0.917
- 0.254
- 0.738
- 0.8
- 0.796
- 0.792
train_loss:
- 2.04
- 0.435
- 1.276
- 1.042
- 0.276
- 1.078
- 0.597
- 0.281
- 0.618
- 0.529
- 0.814
- 0.824
- 0.548
- 0.82
- 0.993
- 0.239
- 0.294
- 0.511
- 0.564
- 0.572
- 0.271
- 0.482
- 0.7
- 0.47
- 0.722
- 0.222
- 0.225
- 0.268
- 0.333
- 0.462
- 0.196
- 0.27
- 0.188
- 0.736
- 0.703
- 0.233
- 0.224
- 0.668
- 0.432
- 0.753
- 0.227
- 0.428
- 0.476
- 0.879
- 0.413
- 0.239
- 0.486
- 0.703
- 0.884
- 0.45
unequal: 0
verbose: 1
