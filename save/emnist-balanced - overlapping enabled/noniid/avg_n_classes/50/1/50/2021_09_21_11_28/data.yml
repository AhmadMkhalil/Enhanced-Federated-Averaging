avg_train_accuracy: 0.788
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.38377659574468087
- 0.5609574468085107
- 0.5945212765957447
- 0.6574468085106383
- 0.6574468085106383
- 0.7031382978723404
- 0.7031382978723404
- 0.7209042553191489
- 0.7292553191489362
- 0.7292553191489362
- 0.737659574468085
- 0.7513297872340425
- 0.7513297872340425
- 0.753031914893617
- 0.753031914893617
- 0.753031914893617
- 0.7542553191489362
- 0.7542553191489362
- 0.7542553191489362
- 0.7542553191489362
- 0.7542553191489362
- 0.7542553191489362
- 0.7542553191489362
- 0.7542553191489362
- 0.7601063829787233
- 0.7687765957446808
- 0.7718085106382979
- 0.7718085106382979
- 0.7718085106382979
- 0.7718085106382979
- 0.7737234042553192
- 0.7737234042553192
- 0.7737234042553192
- 0.7737234042553192
- 0.7737234042553192
- 0.7737234042553192
- 0.7758510638297872
- 0.7758510638297872
- 0.7758510638297872
- 0.7758510638297872
- 0.7794148936170213
- 0.7794148936170213
- 0.7794148936170213
- 0.7794148936170213
- 0.7794148936170213
- 0.7794148936170213
- 0.7794148936170213
- 0.7794148936170213
- 0.7794148936170213
- 0.7794148936170213
test_loss_list:
- 380.9095149040222
- 227.64223420619965
- 198.76063585281372
- 166.5860424041748
- 166.5860424041748
- 142.1600842475891
- 142.1600842475891
- 127.91331708431244
- 124.15084534883499
- 124.15084534883499
- 120.51691883802414
- 117.11744499206543
- 117.11744499206543
- 113.90540850162506
- 113.90540850162506
- 113.90540850162506
- 110.91602122783661
- 110.91602122783661
- 110.91602122783661
- 110.91602122783661
- 110.91602122783661
- 110.91602122783661
- 110.91602122783661
- 110.91602122783661
- 105.03950121998787
- 104.65926420688629
- 102.72366258502007
- 102.72366258502007
- 102.72366258502007
- 102.72366258502007
- 103.13793849945068
- 103.13793849945068
- 103.13793849945068
- 103.13793849945068
- 103.13793849945068
- 103.13793849945068
- 99.84893721342087
- 99.84893721342087
- 99.84893721342087
- 99.84893721342087
- 100.21094331145287
- 100.21094331145287
- 100.21094331145287
- 100.21094331145287
- 100.21094331145287
- 100.21094331145287
- 100.21094331145287
- 100.21094331145287
- 100.21094331145287
- 100.21094331145287
train_accuracy:
- 0.375
- 0.608
- 0.667
- 0.642
- 0.417
- 0.104
- 0.583
- 0.729
- 0.754
- 0.854
- 0.667
- 0.808
- 0.954
- 0.796
- 0.85
- 0.779
- 0.846
- 0.825
- 0.842
- 0.979
- 0.754
- 0.917
- 0.192
- 0.829
- 0.858
- 0.821
- 0.837
- 0.842
- 0.812
- 0.758
- 0.842
- 0.821
- 0.312
- 0.846
- 0.812
- 0.958
- 0.8
- 0.792
- 0.796
- 0.775
- 0.792
- 0.858
- 0.817
- 0.875
- 0.908
- 0.817
- 0.788
- 0.317
- 0.883
- 0.788
train_loss:
- 3.236
- 1.112
- 0.482
- 0.839
- 0.413
- 0.819
- 0.397
- 0.692
- 1.045
- 0.372
- 1.021
- 0.637
- 0.02
- 0.937
- 0.331
- 0.983
- 0.905
- 0.311
- 1.242
- 0.021
- 0.596
- 0.02
- 0.297
- 0.917
- 1.123
- 0.863
- 0.837
- 0.533
- 0.572
- 0.295
- 0.88
- 1.138
- 0.534
- 0.826
- 0.83
- 0.275
- 1.153
- 0.559
- 0.545
- 0.279
- 0.889
- 0.789
- 0.56
- 0.828
- 0.576
- 0.796
- 0.819
- 0.284
- 0.547
- 0.274
unequal: 0
verbose: 1
