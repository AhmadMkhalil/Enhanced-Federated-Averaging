avg_train_accuracy: 0.771
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.36090425531914894
- 0.5473936170212766
- 0.6258510638297873
- 0.642127659574468
- 0.6526595744680851
- 0.6911702127659575
- 0.6911702127659575
- 0.7015957446808511
- 0.7015957446808511
- 0.7015957446808511
- 0.7015957446808511
- 0.7126063829787234
- 0.7126063829787234
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7330851063829787
- 0.7348936170212766
- 0.7348936170212766
- 0.7391489361702127
- 0.7391489361702127
- 0.7391489361702127
- 0.7391489361702127
- 0.7391489361702127
- 0.7412765957446809
- 0.7412765957446809
- 0.7412765957446809
- 0.7573936170212766
- 0.7573936170212766
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
- 0.758031914893617
test_loss_list:
- 352.8955659866333
- 238.01459383964539
- 185.79474413394928
- 171.4323320388794
- 164.00176346302032
- 143.2713778614998
- 143.2713778614998
- 138.525246322155
- 138.525246322155
- 138.525246322155
- 138.525246322155
- 131.92129868268967
- 131.92129868268967
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 123.14066398143768
- 119.5391954779625
- 119.5391954779625
- 113.24361741542816
- 113.24361741542816
- 113.24361741542816
- 113.24361741542816
- 113.24361741542816
- 117.0360170006752
- 117.0360170006752
- 117.0360170006752
- 108.65160900354385
- 108.65160900354385
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
- 109.56288623809814
train_accuracy:
- 0.429
- 0.442
- 0.633
- 0.775
- 0.633
- 0.892
- 0.817
- 0.696
- 0.817
- 0.837
- 0.979
- 0.883
- 0.729
- 0.779
- 0.979
- 0.967
- 0.983
- 0.925
- 0.987
- 0.8
- 0.987
- 0.642
- 0.875
- 0.908
- 0.95
- 0.729
- 0.808
- 0.804
- 0.812
- 0.725
- 0.938
- 0.979
- 0.821
- 0.017
- 0.95
- 0.767
- 0.946
- 0.808
- 0.804
- 0.767
- 0.742
- 0.942
- 0.946
- 0.825
- 0.925
- 0.746
- 0.712
- 0.796
- 0.746
- 0.771
train_loss:
- 0.867
- 0.622
- 1.015
- 0.45
- 0.44
- 0.826
- 0.379
- 0.783
- 0.021
- 0.392
- 0.02
- 0.358
- 0.325
- 0.709
- 0.02
- 0.022
- 0.019
- 0.022
- 0.018
- 0.371
- 0.021
- 0.331
- 0.021
- 0.017
- 0.359
- 0.358
- 0.354
- 0.679
- 0.334
- 0.625
- 0.024
- 0.023
- 0.304
- 0.339
- 0.026
- 0.601
- 0.57
- 0.585
- 0.322
- 0.29
- 0.299
- 0.024
- 0.024
- 0.33
- 0.292
- 0.334
- 0.32
- 0.274
- 0.291
- 0.35
unequal: 0
verbose: 1
