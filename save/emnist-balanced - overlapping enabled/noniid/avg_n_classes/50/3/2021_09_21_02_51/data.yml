avg_train_accuracy: 0.929
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 3
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.3953191489361702
- 0.5670744680851064
- 0.628031914893617
- 0.628031914893617
- 0.661595744680851
- 0.6936170212765957
- 0.7029255319148936
- 0.7139893617021277
- 0.7221276595744681
- 0.7221276595744681
- 0.736968085106383
- 0.7549468085106383
- 0.7549468085106383
- 0.7549468085106383
- 0.7549468085106383
- 0.7598936170212766
- 0.7672872340425532
- 0.7672872340425532
- 0.7672872340425532
- 0.7673936170212766
- 0.7673936170212766
- 0.7673936170212766
- 0.7673936170212766
- 0.7673936170212766
- 0.7673936170212766
- 0.7718085106382979
- 0.7718085106382979
- 0.7718085106382979
- 0.7718085106382979
- 0.773031914893617
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7762765957446809
- 0.7784042553191489
- 0.7784042553191489
- 0.7791489361702127
- 0.7791489361702127
- 0.7791489361702127
test_loss_list:
- 403.0006151199341
- 232.57745027542114
- 184.59366059303284
- 184.59366059303284
- 165.4160423874855
- 144.83889734745026
- 140.34346669912338
- 133.18259006738663
- 130.40163159370422
- 130.40163159370422
- 118.97136896848679
- 115.33510208129883
- 115.33510208129883
- 115.33510208129883
- 115.33510208129883
- 109.14317375421524
- 107.03791582584381
- 107.03791582584381
- 107.03791582584381
- 107.26241847872734
- 107.26241847872734
- 107.26241847872734
- 107.26241847872734
- 107.26241847872734
- 107.26241847872734
- 103.13317894935608
- 103.13317894935608
- 103.13317894935608
- 103.13317894935608
- 101.86276251077652
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 100.4088299870491
- 97.2296000123024
- 97.2296000123024
- 98.5212873518467
- 98.5212873518467
- 98.5212873518467
train_accuracy:
- 0.496
- 0.6
- 0.704
- 0.629
- 0.65
- 0.717
- 0.733
- 0.767
- 0.821
- 0.671
- 0.692
- 0.775
- 0.804
- 0.754
- 0.829
- 0.779
- 0.796
- 0.171
- 0.646
- 0.871
- 0.783
- 0.992
- 0.908
- 0.779
- 0.775
- 0.888
- 0.788
- 0.854
- 0.783
- 0.8
- 0.438
- 0.983
- 0.796
- 0.917
- 0.771
- 0.954
- 0.796
- 0.646
- 0.979
- 0.783
- 0.896
- 0.925
- 0.921
- 0.75
- 0.825
- 0.837
- 0.783
- 0.983
- 0.796
- 0.929
train_loss:
- 2.581
- 1.299
- 1.455
- 0.122
- 0.944
- 0.877
- 0.848
- 0.812
- 0.766
- 0.461
- 1.041
- 1.037
- 0.412
- 0.733
- 0.431
- 1.261
- 1.222
- 0.649
- 0.385
- 0.683
- 0.373
- 0.116
- 0.663
- 0.651
- 0.625
- 0.664
- 0.644
- 0.363
- 0.881
- 0.892
- 0.891
- 0.37
- 0.365
- 0.398
- 0.409
- 0.391
- 0.925
- 0.384
- 0.384
- 0.6
- 0.399
- 0.389
- 0.639
- 0.371
- 0.861
- 0.625
- 0.604
- 0.604
- 0.852
- 0.371
unequal: 0
verbose: 1
