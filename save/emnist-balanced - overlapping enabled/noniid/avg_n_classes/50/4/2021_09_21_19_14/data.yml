avg_train_accuracy: 0.867
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.39622340425531916
- 0.5449468085106383
- 0.6070744680851063
- 0.6562765957446809
- 0.7016489361702127
- 0.715
- 0.7268617021276595
- 0.7268617021276595
- 0.7377659574468085
- 0.7377659574468085
- 0.7377659574468085
- 0.7377659574468085
- 0.7377659574468085
- 0.7534574468085107
- 0.7534574468085107
- 0.7635106382978724
- 0.7635106382978724
- 0.7679787234042553
- 0.7682978723404256
- 0.768563829787234
- 0.768563829787234
- 0.768563829787234
- 0.7745744680851064
- 0.7745744680851064
- 0.7745744680851064
- 0.7763297872340426
- 0.7763297872340426
- 0.7763297872340426
- 0.7763297872340426
- 0.7779787234042553
- 0.7779787234042553
- 0.7779787234042553
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7867021276595745
- 0.7874468085106383
- 0.7874468085106383
- 0.7874468085106383
- 0.7874468085106383
- 0.7875531914893616
test_loss_list:
- 399.62310242652893
- 248.81290805339813
- 201.12261962890625
- 169.53172993659973
- 145.35258275270462
- 136.39396119117737
- 127.7571285367012
- 127.7571285367012
- 123.11842238903046
- 123.11842238903046
- 123.11842238903046
- 123.11842238903046
- 123.11842238903046
- 112.02949005365372
- 112.02949005365372
- 107.1992118358612
- 107.1992118358612
- 105.70198267698288
- 104.60369825363159
- 105.08796799182892
- 105.08796799182892
- 105.08796799182892
- 102.51133853197098
- 102.51133853197098
- 102.51133853197098
- 101.52596271038055
- 101.52596271038055
- 101.52596271038055
- 101.52596271038055
- 98.85412776470184
- 98.85412776470184
- 98.85412776470184
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 96.60953173041344
- 95.17886513471603
- 95.17886513471603
- 95.17886513471603
- 95.17886513471603
- 95.13709923624992
train_accuracy:
- 0.042
- 0.562
- 0.646
- 0.946
- 0.717
- 0.779
- 0.708
- 0.758
- 0.796
- 0.742
- 0.754
- 0.858
- 0.8
- 0.812
- 0.746
- 0.812
- 0.25
- 0.75
- 0.792
- 0.471
- 0.717
- 0.821
- 0.783
- 0.4
- 0.871
- 0.833
- 0.779
- 0.75
- 0.871
- 0.942
- 0.808
- 0.85
- 0.817
- 0.808
- 0.767
- 0.808
- 0.825
- 0.858
- 0.812
- 0.925
- 0.775
- 0.792
- 0.892
- 0.796
- 1.0
- 0.933
- 0.954
- 0.808
- 0.825
- 0.867
train_loss:
- 1.864
- 1.245
- 1.038
- 0.945
- 1.211
- 1.161
- 1.135
- 1.105
- 0.851
- 0.745
- 1.28
- 0.52
- 0.723
- 0.963
- 0.733
- 0.702
- 0.499
- 0.992
- 0.659
- 0.703
- 0.931
- 0.912
- 0.95
- 0.431
- 0.665
- 0.65
- 0.874
- 0.87
- 0.644
- 0.892
- 0.65
- 0.639
- 0.87
- 0.837
- 1.085
- 0.669
- 0.685
- 0.417
- 0.871
- 0.164
- 0.653
- 0.387
- 0.402
- 0.593
- 0.194
- 0.579
- 0.39
- 0.903
- 0.837
- 0.603
unequal: 0
verbose: 1
