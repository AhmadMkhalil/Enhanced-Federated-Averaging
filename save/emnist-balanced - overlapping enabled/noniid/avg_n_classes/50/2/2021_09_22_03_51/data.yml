avg_train_accuracy: 0.796
avg_train_loss: 0.006
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.37659574468085105
- 0.5309574468085106
- 0.6229255319148936
- 0.6598936170212766
- 0.686968085106383
- 0.686968085106383
- 0.7061702127659575
- 0.7061702127659575
- 0.7223404255319149
- 0.7322872340425531
- 0.7343617021276596
- 0.7343617021276596
- 0.7429787234042553
- 0.7429787234042553
- 0.7447872340425532
- 0.7447872340425532
- 0.7527127659574468
- 0.7527127659574468
- 0.7527127659574468
- 0.7634042553191489
- 0.7634042553191489
- 0.7634042553191489
- 0.7647340425531914
- 0.7647340425531914
- 0.7647340425531914
- 0.7647340425531914
- 0.7647340425531914
- 0.7699468085106383
- 0.7699468085106383
- 0.7699468085106383
- 0.7699468085106383
- 0.7699468085106383
- 0.7699468085106383
- 0.7699468085106383
- 0.7724468085106383
- 0.7724468085106383
- 0.7724468085106383
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
- 0.7733510638297872
test_loss_list:
- 366.9805464744568
- 251.25101780891418
- 198.0555602312088
- 164.64814239740372
- 151.2441149353981
- 151.2441149353981
- 135.03737711906433
- 135.03737711906433
- 127.13429033756256
- 122.14806061983109
- 119.37823808193207
- 119.37823808193207
- 113.4956219792366
- 113.4956219792366
- 113.16296881437302
- 113.16296881437302
- 110.76979953050613
- 110.76979953050613
- 110.76979953050613
- 106.02187359333038
- 106.02187359333038
- 106.02187359333038
- 105.6600940823555
- 105.6600940823555
- 105.6600940823555
- 105.6600940823555
- 105.6600940823555
- 104.35937735438347
- 104.35937735438347
- 104.35937735438347
- 104.35937735438347
- 104.35937735438347
- 104.35937735438347
- 104.35937735438347
- 100.65991219878197
- 100.65991219878197
- 100.65991219878197
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
- 99.86600005626678
train_accuracy:
- 0.0
- 0.546
- 0.658
- 0.721
- 0.738
- 0.758
- 0.758
- 0.121
- 0.796
- 0.721
- 0.779
- 0.779
- 0.746
- 0.871
- 0.746
- 0.775
- 0.862
- 0.808
- 0.758
- 0.788
- 0.771
- 0.767
- 0.792
- 0.746
- 0.8
- 0.758
- 0.725
- 0.767
- 0.792
- 0.933
- 0.812
- 0.788
- 0.488
- 0.825
- 0.788
- 0.833
- 0.938
- 0.812
- 0.867
- 0.775
- 0.804
- 0.913
- 0.808
- 0.921
- 0.696
- 0.814
- 0.862
- 0.775
- 0.821
- 0.796
train_loss:
- 0.956
- 1.216
- 1.507
- 1.322
- 1.607
- 0.431
- 1.109
- 0.452
- 1.094
- 0.73
- 1.012
- 1.042
- 0.94
- 0.378
- 0.997
- 0.951
- 0.66
- 0.933
- 0.637
- 1.18
- 0.633
- 0.655
- 0.903
- 0.372
- 0.892
- 0.335
- 0.348
- 0.644
- 0.608
- 0.626
- 1.176
- 0.597
- 0.371
- 0.914
- 0.587
- 1.127
- 0.351
- 0.665
- 0.368
- 0.609
- 0.854
- 0.866
- 0.55
- 0.824
- 0.35
- 0.337
- 0.596
- 0.857
- 0.591
- 0.593
unequal: 0
verbose: 1
