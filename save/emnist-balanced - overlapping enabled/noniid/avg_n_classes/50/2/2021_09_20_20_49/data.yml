avg_train_accuracy: 0.788
avg_train_loss: 0.008
avg_type: avg_n_classes
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.38351063829787235
- 0.5523936170212767
- 0.6092553191489362
- 0.6410106382978723
- 0.6410106382978723
- 0.6653191489361702
- 0.6653191489361702
- 0.7099468085106383
- 0.7099468085106383
- 0.7099468085106383
- 0.7218617021276595
- 0.741968085106383
- 0.741968085106383
- 0.741968085106383
- 0.741968085106383
- 0.741968085106383
- 0.741968085106383
- 0.7500531914893617
- 0.7500531914893617
- 0.7524468085106383
- 0.7535106382978723
- 0.7535106382978723
- 0.7535106382978723
- 0.7572872340425532
- 0.7572872340425532
- 0.7572872340425532
- 0.7572872340425532
- 0.7632978723404256
- 0.7652659574468085
- 0.767127659574468
- 0.767127659574468
- 0.767127659574468
- 0.767127659574468
- 0.767127659574468
- 0.767127659574468
- 0.7674468085106383
- 0.7679255319148937
- 0.7679255319148937
- 0.7679255319148937
- 0.7679255319148937
- 0.7679255319148937
- 0.7679255319148937
- 0.7679255319148937
- 0.7679255319148937
- 0.7751063829787234
- 0.7778191489361702
- 0.7778191489361702
- 0.7778191489361702
- 0.7778191489361702
- 0.7789893617021276
test_loss_list:
- 392.0816967487335
- 234.00406455993652
- 192.70190942287445
- 176.20019847154617
- 176.20019847154617
- 164.87469375133514
- 164.87469375133514
- 135.81323432922363
- 135.81323432922363
- 135.81323432922363
- 129.04950672388077
- 122.44897723197937
- 122.44897723197937
- 122.44897723197937
- 122.44897723197937
- 122.44897723197937
- 122.44897723197937
- 113.13251584768295
- 113.13251584768295
- 110.15660572052002
- 111.37944692373276
- 111.37944692373276
- 111.37944692373276
- 105.776222884655
- 105.776222884655
- 105.776222884655
- 105.776222884655
- 104.87430569529533
- 102.28259363770485
- 102.584930062294
- 102.584930062294
- 102.584930062294
- 102.584930062294
- 102.584930062294
- 102.584930062294
- 105.46285235881805
- 102.65742495656013
- 102.65742495656013
- 102.65742495656013
- 102.65742495656013
- 102.65742495656013
- 102.65742495656013
- 102.65742495656013
- 102.65742495656013
- 99.96590557694435
- 98.47875747084618
- 98.47875747084618
- 98.47875747084618
- 98.47875747084618
- 96.87018576264381
train_accuracy:
- 0.062
- 0.65
- 0.488
- 0.779
- 0.792
- 0.692
- 0.837
- 0.871
- 0.667
- 0.775
- 0.783
- 0.796
- 0.829
- 0.829
- 0.808
- 0.775
- 0.962
- 0.788
- 0.754
- 0.8
- 0.817
- 0.771
- 0.738
- 0.754
- 0.842
- 0.808
- 0.888
- 0.754
- 0.817
- 0.804
- 0.779
- 0.8
- 0.979
- 0.071
- 0.812
- 0.829
- 0.762
- 0.754
- 0.783
- 0.775
- 0.825
- 0.958
- 0.904
- 0.229
- 0.792
- 0.783
- 0.771
- 0.788
- 0.883
- 0.788
train_loss:
- 2.506
- 1.697
- 0.941
- 0.496
- 0.104
- 0.866
- 0.487
- 0.777
- 0.785
- 0.401
- 1.074
- 1.009
- 0.359
- 0.401
- 1.04
- 0.404
- 0.103
- 0.647
- 0.387
- 1.188
- 0.959
- 0.345
- 0.927
- 0.894
- 0.343
- 0.372
- 0.351
- 0.619
- 1.144
- 0.638
- 0.32
- 0.635
- 0.06
- 0.33
- 0.559
- 0.363
- 0.631
- 0.297
- 0.883
- 0.551
- 0.604
- 0.33
- 0.343
- 0.331
- 0.911
- 0.817
- 0.546
- 0.821
- 0.075
- 0.814
unequal: 0
verbose: 1
