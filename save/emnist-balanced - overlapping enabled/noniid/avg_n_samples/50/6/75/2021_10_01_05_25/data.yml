avg_train_accuracy: 0.329
avg_train_loss: 0.002
avg_type: avg_n_samples
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 6
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.08393617021276596
- 0.20643617021276595
- 0.20643617021276595
- 0.3145212765957447
- 0.5678723404255319
- 0.5678723404255319
- 0.5678723404255319
- 0.5678723404255319
- 0.5678723404255319
- 0.5678723404255319
- 0.5678723404255319
- 0.5678723404255319
- 0.5678723404255319
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6771276595744681
- 0.6873404255319149
- 0.6873404255319149
- 0.6873404255319149
- 0.6873404255319149
- 0.6873404255319149
- 0.6873404255319149
- 0.6873404255319149
- 0.6873404255319149
- 0.6873404255319149
test_loss_list:
- 568.5045590400696
- 476.83811140060425
- 476.83811140060425
- 344.3110406398773
- 209.0211807489395
- 209.0211807489395
- 209.0211807489395
- 209.0211807489395
- 209.0211807489395
- 209.0211807489395
- 209.0211807489395
- 209.0211807489395
- 209.0211807489395
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 149.11273711919785
- 136.77357983589172
- 136.77357983589172
- 136.77357983589172
- 136.77357983589172
- 136.77357983589172
- 136.77357983589172
- 136.77357983589172
- 136.77357983589172
- 136.77357983589172
train_accuracy:
- 0.154
- 0.179
- 0.125
- 0.267
- 0.583
- 0.379
- 0.5
- 0.158
- 0.142
- 0.808
- 0.408
- 0.05
- 0.562
- 0.658
- 0.625
- 0.663
- 0.558
- 0.417
- 0.571
- 0.683
- 0.467
- 0.663
- 0.354
- 0.904
- 0.529
- 0.775
- 0.512
- 0.292
- 0.292
- 0.358
- 0.296
- 0.7
- 0.962
- 0.429
- 0.925
- 0.363
- 0.846
- 0.825
- 0.525
- 0.475
- 0.888
- 0.5
- 0.587
- 0.85
- 0.458
- 0.958
- 0.767
- 0.55
- 1.0
- 0.329
train_loss:
- 0.749
- 1.093
- 0.985
- 0.814
- 1.559
- 0.3
- 0.723
- 0.259
- 0.627
- 0.653
- 0.23
- 0.552
- 0.62
- 1.191
- 0.843
- 0.277
- 0.841
- 0.515
- 0.78
- 0.524
- 0.542
- 0.545
- 0.508
- 0.214
- 0.582
- 0.484
- 0.274
- 0.282
- 0.555
- 0.537
- 0.211
- 0.731
- 0.159
- 0.555
- 0.258
- 0.275
- 0.176
- 0.213
- 0.466
- 0.447
- 0.458
- 0.739
- 0.206
- 0.219
- 0.207
- 0.217
- 0.473
- 0.264
- 0.169
- 0.237
unequal: 0
verbose: 1
