avg_train_accuracy: 0.962
avg_train_loss: 0.006
avg_type: avg_n_samples
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 2
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.09117021276595745
- 0.4341489361702128
- 0.4341489361702128
- 0.4341489361702128
- 0.5709574468085107
- 0.5709574468085107
- 0.5709574468085107
- 0.5709574468085107
- 0.5709574468085107
- 0.5826595744680851
- 0.6602659574468085
- 0.6602659574468085
- 0.6927127659574468
- 0.7232446808510639
- 0.7232446808510639
- 0.7232446808510639
- 0.7232446808510639
- 0.7232446808510639
- 0.7248404255319149
- 0.7248404255319149
- 0.7248404255319149
- 0.7248404255319149
- 0.7248404255319149
- 0.7396276595744681
- 0.7396276595744681
- 0.7396276595744681
- 0.7396276595744681
- 0.7396276595744681
- 0.7396276595744681
- 0.7396276595744681
- 0.7409042553191489
- 0.7409042553191489
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7539893617021277
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
- 0.7630851063829788
test_loss_list:
- 498.60825181007385
- 306.21970331668854
- 306.21970331668854
- 306.21970331668854
- 208.89500164985657
- 208.89500164985657
- 208.89500164985657
- 208.89500164985657
- 208.89500164985657
- 197.74886882305145
- 158.514318048954
- 158.514318048954
- 137.36656910181046
- 125.8805587887764
- 125.8805587887764
- 125.8805587887764
- 125.8805587887764
- 125.8805587887764
- 125.1439877152443
- 125.1439877152443
- 125.1439877152443
- 125.1439877152443
- 125.1439877152443
- 118.7445495724678
- 118.7445495724678
- 118.7445495724678
- 118.7445495724678
- 118.7445495724678
- 118.7445495724678
- 118.7445495724678
- 114.69039046764374
- 114.69039046764374
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 112.05527228116989
- 104.70800358057022
- 104.70800358057022
- 104.70800358057022
- 104.70800358057022
- 104.70800358057022
- 104.70800358057022
- 104.70800358057022
train_accuracy:
- 0.087
- 0.488
- 0.788
- 0.892
- 0.967
- 0.921
- 0.542
- 0.496
- 0.921
- 0.554
- 0.646
- 1.0
- 0.704
- 0.729
- 0.913
- 0.717
- 0.688
- 0.825
- 0.971
- 0.771
- 0.975
- 0.962
- 0.733
- 0.817
- 0.788
- 0.962
- 0.671
- 0.967
- 0.704
- 0.954
- 0.979
- 0.683
- 0.779
- 0.729
- 0.938
- 0.95
- 0.758
- 0.512
- 0.738
- 0.979
- 0.717
- 0.975
- 0.708
- 0.771
- 0.962
- 0.158
- 0.738
- 0.992
- 0.975
- 0.962
train_loss:
- 1.701
- 1.895
- 0.062
- 0.55
- 1.457
- 0.522
- 0.883
- 0.865
- 0.431
- 0.784
- 0.805
- 0.412
- 1.09
- 1.356
- 0.387
- 0.729
- 0.7
- 0.073
- 1.03
- 0.714
- 0.672
- 0.401
- 0.694
- 0.968
- 0.931
- 0.655
- 0.607
- 0.366
- 0.708
- 0.636
- 0.915
- 0.62
- 0.94
- 0.898
- 0.914
- 0.349
- 0.878
- 0.627
- 0.596
- 0.044
- 0.591
- 0.304
- 0.619
- 0.875
- 0.298
- 0.582
- 0.585
- 0.326
- 0.566
- 0.578
unequal: 0
verbose: 1
