avg_train_accuracy: 0.729
avg_train_loss: 0.004
avg_type: avg_n_samples
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1026595744680851
- 0.3521808510638298
- 0.3521808510638298
- 0.37409574468085105
- 0.5678191489361702
- 0.5678191489361702
- 0.5678191489361702
- 0.5678191489361702
- 0.6923936170212766
- 0.6923936170212766
- 0.6923936170212766
- 0.6923936170212766
- 0.6923936170212766
- 0.6923936170212766
- 0.7182978723404255
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7498936170212765
- 0.7599468085106383
- 0.7599468085106383
- 0.7599468085106383
- 0.7657978723404255
- 0.7657978723404255
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
- 0.77
test_loss_list:
- 484.6577365398407
- 331.2251763343811
- 331.2251763343811
- 297.57280027866364
- 199.94910073280334
- 199.94910073280334
- 199.94910073280334
- 199.94910073280334
- 145.32221883535385
- 145.32221883535385
- 145.32221883535385
- 145.32221883535385
- 145.32221883535385
- 145.32221883535385
- 126.04075926542282
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 112.75067454576492
- 107.36935675144196
- 107.36935675144196
- 107.36935675144196
- 101.68386620283127
- 101.68386620283127
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
- 100.79590356349945
train_accuracy:
- 0.613
- 0.342
- 0.967
- 0.421
- 0.75
- 0.512
- 0.442
- 0.483
- 0.925
- 0.983
- 0.738
- 0.983
- 0.862
- 0.929
- 0.721
- 0.779
- 0.725
- 0.708
- 0.554
- 0.992
- 0.938
- 0.958
- 0.979
- 0.683
- 0.967
- 0.667
- 0.971
- 0.712
- 0.987
- 0.913
- 0.808
- 0.975
- 0.792
- 0.983
- 0.7
- 0.729
- 0.667
- 0.696
- 0.75
- 0.762
- 0.862
- 0.658
- 0.783
- 0.888
- 0.867
- 0.771
- 0.717
- 0.817
- 0.692
- 0.729
train_loss:
- 1.869
- 1.331
- 1.203
- 1.06
- 0.922
- 0.184
- 0.892
- 0.843
- 1.152
- 0.811
- 1.084
- 0.778
- 0.804
- 0.436
- 1.009
- 1.302
- 0.679
- 0.746
- 0.485
- 0.391
- 1.002
- 0.686
- 0.714
- 0.708
- 0.397
- 0.746
- 0.392
- 0.921
- 0.732
- 0.431
- 1.18
- 0.665
- 1.147
- 0.397
- 0.665
- 0.895
- 0.425
- 0.62
- 0.671
- 0.951
- 0.452
- 0.618
- 0.613
- 0.656
- 0.429
- 0.84
- 0.633
- 1.094
- 0.618
- 0.384
unequal: 0
verbose: 1
