avg_train_accuracy: 0.862
avg_train_loss: 0.006
avg_type: avg_n_samples
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 4
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.16026595744680852
- 0.2326063829787234
- 0.390531914893617
- 0.46925531914893615
- 0.46925531914893615
- 0.6354787234042554
- 0.6354787234042554
- 0.6354787234042554
- 0.6437765957446808
- 0.6437765957446808
- 0.6437765957446808
- 0.6437765957446808
- 0.6437765957446808
- 0.6437765957446808
- 0.6437765957446808
- 0.7088297872340426
- 0.7088297872340426
- 0.7088297872340426
- 0.7168617021276595
- 0.7168617021276595
- 0.7168617021276595
- 0.7168617021276595
- 0.7168617021276595
- 0.7168617021276595
- 0.7168617021276595
- 0.7210106382978724
- 0.7210106382978724
- 0.7210106382978724
- 0.7298404255319149
- 0.7492553191489362
- 0.7492553191489362
- 0.7492553191489362
- 0.7588829787234043
- 0.7588829787234043
- 0.7588829787234043
- 0.7588829787234043
- 0.7588829787234043
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
- 0.7635106382978724
test_loss_list:
- 493.835045337677
- 396.84828519821167
- 287.4877836704254
- 239.0323861837387
- 239.0323861837387
- 176.0587803721428
- 176.0587803721428
- 176.0587803721428
- 165.00688695907593
- 165.00688695907593
- 165.00688695907593
- 165.00688695907593
- 165.00688695907593
- 165.00688695907593
- 165.00688695907593
- 131.00762271881104
- 131.00762271881104
- 131.00762271881104
- 122.44754022359848
- 122.44754022359848
- 122.44754022359848
- 122.44754022359848
- 122.44754022359848
- 122.44754022359848
- 122.44754022359848
- 123.41290748119354
- 123.41290748119354
- 123.41290748119354
- 121.70160120725632
- 113.34028899669647
- 113.34028899669647
- 113.34028899669647
- 109.83558213710785
- 109.83558213710785
- 109.83558213710785
- 109.83558213710785
- 109.83558213710785
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
- 101.25169298052788
train_accuracy:
- 0.125
- 0.204
- 0.979
- 0.467
- 0.854
- 0.704
- 0.587
- 0.942
- 0.633
- 0.946
- 0.883
- 0.996
- 0.533
- 0.492
- 0.579
- 0.738
- 0.658
- 0.987
- 0.871
- 0.637
- 0.637
- 0.921
- 0.888
- 0.738
- 0.913
- 0.708
- 0.663
- 1.0
- 0.75
- 0.746
- 0.908
- 0.933
- 0.796
- 0.95
- 0.921
- 0.117
- 0.775
- 0.817
- 0.983
- 0.708
- 0.842
- 0.221
- 0.692
- 0.954
- 0.692
- 0.946
- 0.754
- 0.967
- 0.979
- 0.862
train_loss:
- 1.93
- 1.366
- 1.191
- 1.034
- 0.646
- 1.307
- 0.558
- 0.548
- 1.231
- 0.586
- 0.846
- 0.522
- 0.487
- 0.898
- 0.76
- 1.111
- 0.788
- 0.774
- 1.044
- 0.726
- 0.726
- 0.729
- 0.705
- 0.696
- 0.739
- 0.719
- 0.665
- 0.703
- 0.955
- 0.924
- 0.412
- 0.139
- 0.95
- 0.684
- 0.163
- 0.449
- 0.949
- 1.144
- 0.405
- 0.695
- 0.885
- 0.422
- 0.426
- 0.398
- 0.675
- 0.637
- 0.855
- 0.621
- 0.608
- 0.602
unequal: 0
verbose: 1
