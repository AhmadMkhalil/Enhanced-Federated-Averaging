avg_train_accuracy: 0.758
avg_train_loss: 0.007
avg_type: avg_n_samples
dataset: emnist-balanced
epochs: 50
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 47
number_of_classes_of_half_of_user: 1
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.02797872340425532
- 0.054787234042553194
- 0.07452127659574469
- 0.37340425531914895
- 0.37340425531914895
- 0.5191489361702127
- 0.5191489361702127
- 0.5191489361702127
- 0.5191489361702127
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6094148936170213
- 0.6622340425531915
- 0.6622340425531915
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.6904787234042553
- 0.711968085106383
- 0.711968085106383
- 0.711968085106383
- 0.711968085106383
- 0.711968085106383
- 0.711968085106383
- 0.711968085106383
- 0.7265425531914894
test_loss_list:
- 1067.0457653999329
- 699.688937664032
- 662.9389276504517
- 311.0422831773758
- 311.0422831773758
- 239.21334099769592
- 239.21334099769592
- 239.21334099769592
- 239.21334099769592
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 183.39068001508713
- 168.40134650468826
- 168.40134650468826
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 142.45556396245956
- 132.03111571073532
- 132.03111571073532
- 132.03111571073532
- 132.03111571073532
- 132.03111571073532
- 132.03111571073532
- 132.03111571073532
- 119.81129848957062
train_accuracy:
- 0.038
- 0.704
- 0.954
- 0.371
- 0.888
- 0.504
- 0.733
- 0.983
- 0.408
- 0.646
- 0.529
- 0.967
- 0.904
- 0.542
- 0.992
- 0.983
- 0.917
- 0.979
- 0.913
- 0.979
- 0.95
- 0.95
- 0.962
- 0.971
- 0.938
- 0.954
- 0.871
- 0.95
- 0.971
- 0.979
- 0.896
- 0.996
- 0.9
- 0.946
- 0.954
- 0.971
- 0.708
- 0.938
- 0.962
- 0.987
- 0.987
- 0.975
- 0.992
- 0.967
- 0.954
- 0.987
- 0.621
- 0.683
- 0.987
- 0.758
train_loss:
- 0.865
- 0.694
- 0.623
- 1.117
- 0.502
- 0.964
- 0.013
- 0.01
- 0.462
- 1.305
- 0.419
- 0.013
- 0.012
- 0.82
- 0.012
- 0.39
- 0.403
- 0.011
- 0.367
- 0.013
- 0.405
- 0.763
- 0.39
- 0.735
- 0.716
- 0.37
- 0.359
- 0.016
- 0.014
- 0.352
- 0.34
- 0.014
- 0.014
- 0.012
- 0.36
- 0.33
- 0.676
- 0.326
- 0.318
- 0.326
- 0.351
- 0.313
- 0.67
- 0.013
- 0.343
- 0.014
- 0.32
- 0.658
- 0.318
- 0.651
unequal: 0
verbose: 1
