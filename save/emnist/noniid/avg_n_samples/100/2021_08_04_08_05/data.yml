avg_train_accuracy: 0.519
avg_train_loss: 0.003
avg_type: avg_n_samples
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.16154255319148936
- 0.23420212765957446
- 0.3196276595744681
- 0.3878723404255319
- 0.36675531914893617
- 0.4368085106382979
- 0.4346276595744681
- 0.4978191489361702
- 0.5513297872340426
- 0.5697340425531915
- 0.5172872340425532
- 0.5386702127659575
- 0.558031914893617
- 0.5632978723404255
- 0.5787765957446809
- 0.5302127659574468
- 0.574627659574468
- 0.5924468085106382
- 0.586968085106383
- 0.5582446808510638
- 0.6428723404255319
- 0.5962234042553192
- 0.6502659574468085
- 0.5662765957446808
- 0.6288297872340426
- 0.6080851063829787
- 0.5756382978723404
- 0.6403191489361703
- 0.585
- 0.6533510638297872
- 0.5848936170212766
- 0.6331382978723404
- 0.6402659574468085
- 0.5896808510638298
- 0.6306914893617022
- 0.5759574468085107
- 0.6740425531914893
- 0.6682978723404255
- 0.6095744680851064
- 0.5729255319148936
- 0.6251063829787235
- 0.6688297872340425
- 0.6404255319148936
- 0.5919148936170213
- 0.6329255319148936
- 0.5750531914893617
- 0.593404255319149
- 0.663031914893617
- 0.6362234042553192
- 0.6311702127659574
- 0.6594148936170213
- 0.6791489361702128
- 0.6635106382978724
- 0.6233510638297872
- 0.6961702127659575
- 0.6525531914893618
- 0.6781382978723405
- 0.6741489361702128
- 0.7169148936170213
- 0.6517021276595745
- 0.6566489361702128
- 0.600531914893617
- 0.6081914893617021
- 0.6782446808510638
- 0.6756914893617021
- 0.6375531914893617
- 0.6912765957446808
- 0.6556382978723404
- 0.6351595744680851
- 0.6124468085106383
- 0.6637765957446808
- 0.6552127659574468
- 0.6123936170212766
- 0.6323936170212766
- 0.6649468085106383
- 0.6159042553191489
- 0.6514893617021277
- 0.6666489361702128
- 0.6698936170212766
- 0.6216489361702128
- 0.6509574468085106
- 0.699627659574468
- 0.6212234042553192
- 0.6829255319148936
- 0.7064893617021276
- 0.6688829787234043
- 0.6561702127659574
- 0.6299468085106383
- 0.6882978723404255
- 0.6777659574468086
- 0.6608510638297872
- 0.6503723404255319
- 0.6692553191489362
- 0.6696808510638298
- 0.6470212765957447
- 0.6540425531914894
- 0.644468085106383
- 0.6954255319148936
- 0.6901063829787234
- 0.6876063829787235
test_loss_list:
- 530.1401944160461
- 439.1459014415741
- 385.3948197364807
- 328.31390047073364
- 333.1784564256668
- 274.03910434246063
- 268.3179829120636
- 238.7947245836258
- 208.30238449573517
- 202.77263057231903
- 210.83252048492432
- 198.72615313529968
- 193.80880296230316
- 199.8710174560547
- 185.00066447257996
- 207.87072002887726
- 182.60226726531982
- 180.41813331842422
- 177.56837856769562
- 200.57660233974457
- 165.88711839914322
- 176.74882888793945
- 152.85987269878387
- 178.9266632795334
- 156.49573177099228
- 163.3115417957306
- 179.26885318756104
- 144.99500727653503
- 197.71454691886902
- 152.4118749499321
- 180.10494583845139
- 160.1113319993019
- 157.2133412361145
- 190.31447684764862
- 161.88569259643555
- 184.4097256064415
- 144.4352788925171
- 149.35318434238434
- 164.3836362361908
- 178.4739340543747
- 160.02585965394974
- 138.75619560480118
- 149.9639257788658
- 180.20235466957092
- 145.41233164072037
- 169.83610326051712
- 162.7942179441452
- 146.99580919742584
- 154.436352789402
- 156.7200495004654
- 142.4052386879921
- 140.9962003827095
- 147.53514194488525
- 161.71411180496216
- 130.90961104631424
- 142.71017599105835
- 135.90887868404388
- 133.3792889714241
- 120.83401364088058
- 156.4799365401268
- 145.24357497692108
- 160.03555303812027
- 156.1848827600479
- 128.54424482584
- 139.2327498793602
- 146.34942430257797
- 129.5381338596344
- 149.76016360521317
- 152.0572236776352
- 157.21956431865692
- 139.7925182580948
- 143.25563019514084
- 159.25524532794952
- 143.2628317475319
- 146.82728379964828
- 157.49893748760223
- 143.31380742788315
- 143.83372235298157
- 144.28044211864471
- 146.71527993679047
- 141.39972484111786
- 126.94026654958725
- 158.164144217968
- 128.2249819636345
- 124.13141882419586
- 139.70881694555283
- 134.65294802188873
- 156.2088105082512
- 128.93256145715714
- 135.97827923297882
- 147.10345524549484
- 151.27752631902695
- 136.51592218875885
- 144.77372634410858
- 157.78567081689835
- 142.0261431336403
- 134.35463362932205
- 129.8021445274353
- 132.27191936969757
- 131.59662878513336
train_accuracy:
- 0.275
- 0.027
- 0.015
- 0.13
- 0.878
- 0.538
- 0.787
- 0.593
- 0.518
- 0.36
- 0.838
- 0.311
- 0.162
- 0.669
- 0.564
- 0.49
- 0.364
- 0.587
- 0.75
- 0.436
- 0.185
- 0.783
- 0.912
- 0.22
- 0.607
- 0.705
- 0.59
- 0.795
- 0.567
- 0.541
- 0.117
- 0.49
- 0.9
- 0.683
- 0.9
- 0.708
- 0.603
- 0.867
- 0.923
- 0.469
- 0.892
- 0.641
- 0.377
- 0.892
- 0.809
- 0.231
- 0.862
- 0.623
- 0.884
- 0.603
- 0.815
- 0.433
- 0.763
- 0.2
- 0.832
- 0.839
- 0.43
- 0.928
- 0.91
- 0.544
- 0.78
- 0.606
- 0.45
- 0.581
- 0.856
- 0.418
- 0.708
- 0.908
- 0.769
- 0.467
- 0.719
- 0.881
- 0.581
- 0.936
- 0.736
- 0.95
- 0.65
- 0.838
- 0.368
- 0.906
- 0.523
- 0.877
- 0.606
- 0.457
- 0.934
- 0.957
- 0.6
- 0.578
- 0.694
- 0.925
- 0.47
- 0.82
- 0.567
- 0.694
- 0.6
- 0.292
- 0.758
- 0.825
- 0.633
- 0.519
train_loss:
- 1.256
- 0.918
- 0.735
- 0.613
- 0.57
- 0.647
- 0.426
- 0.555
- 0.533
- 0.442
- 0.44
- 0.436
- 0.437
- 0.472
- 0.415
- 0.364
- 0.405
- 0.437
- 0.425
- 0.399
- 0.42
- 0.342
- 0.365
- 0.352
- 0.421
- 0.42
- 0.434
- 0.4
- 0.315
- 0.318
- 0.369
- 0.421
- 0.481
- 0.394
- 0.402
- 0.378
- 0.419
- 0.403
- 0.402
- 0.433
- 0.337
- 0.324
- 0.372
- 0.333
- 0.432
- 0.31
- 0.375
- 0.348
- 0.289
- 0.366
- 0.361
- 0.269
- 0.399
- 0.353
- 0.334
- 0.349
- 0.305
- 0.347
- 0.358
- 0.34
- 0.324
- 0.358
- 0.359
- 0.383
- 0.322
- 0.401
- 0.323
- 0.355
- 0.308
- 0.349
- 0.386
- 0.342
- 0.349
- 0.39
- 0.309
- 0.312
- 0.402
- 0.331
- 0.359
- 0.382
- 0.371
- 0.337
- 0.376
- 0.341
- 0.339
- 0.398
- 0.358
- 0.402
- 0.422
- 0.353
- 0.39
- 0.322
- 0.347
- 0.389
- 0.325
- 0.41
- 0.325
- 0.325
- 0.284
- 0.337
unequal: 1
verbose: 1
