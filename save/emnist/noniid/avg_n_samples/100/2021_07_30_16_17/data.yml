avg_train_accuracy: 0.343
avg_train_loss: 0.003
avg_type: avg_n_samples
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.18936170212765957
- 0.24553191489361703
- 0.3748404255319149
- 0.37920212765957445
- 0.4548404255319149
- 0.42281914893617023
- 0.4523404255319149
- 0.4753191489361702
- 0.4957446808510638
- 0.535372340425532
- 0.5201595744680851
- 0.49638297872340426
- 0.5398936170212766
- 0.52
- 0.555
- 0.6097340425531915
- 0.601436170212766
- 0.5875531914893617
- 0.6338297872340426
- 0.5766489361702127
- 0.585
- 0.5793617021276596
- 0.5725
- 0.6426063829787234
- 0.5849468085106383
- 0.5622872340425532
- 0.5570744680851064
- 0.6671808510638297
- 0.6545744680851063
- 0.5621808510638298
- 0.6427127659574469
- 0.5879255319148936
- 0.6423936170212766
- 0.6035106382978723
- 0.5654787234042553
- 0.5327659574468085
- 0.6046276595744681
- 0.5571808510638298
- 0.5913829787234043
- 0.6336702127659575
- 0.5941489361702128
- 0.5613297872340426
- 0.632127659574468
- 0.6158510638297873
- 0.6137765957446808
- 0.5989361702127659
- 0.6213829787234042
- 0.5721808510638298
- 0.6480851063829787
- 0.6581382978723405
- 0.6018617021276595
- 0.6149468085106383
- 0.6651595744680852
- 0.6631914893617021
- 0.658936170212766
- 0.5765425531914894
- 0.6547340425531915
- 0.6382446808510638
- 0.5810106382978724
- 0.5883510638297872
- 0.6407978723404255
- 0.6319148936170212
- 0.6400531914893617
- 0.5881914893617022
- 0.6663297872340426
- 0.6733510638297873
- 0.665904255319149
- 0.7073936170212766
- 0.6132446808510639
- 0.5835106382978723
- 0.6507978723404255
- 0.6755851063829788
- 0.5670744680851064
- 0.6113297872340425
- 0.6720744680851064
- 0.6540425531914894
- 0.651436170212766
- 0.6482446808510638
- 0.6768085106382978
- 0.706063829787234
- 0.6673404255319149
- 0.6398404255319149
- 0.6615425531914894
- 0.6821276595744681
- 0.6350531914893617
- 0.6518617021276596
- 0.671063829787234
- 0.6603191489361702
- 0.6720212765957447
- 0.7090425531914893
- 0.7009042553191489
- 0.6398936170212766
- 0.6384042553191489
- 0.6167553191489362
- 0.6165957446808511
- 0.6065425531914893
- 0.6614361702127659
- 0.6590957446808511
- 0.659468085106383
- 0.6153723404255319
test_loss_list:
- 528.0821340084076
- 446.9154427051544
- 354.0491449832916
- 310.0441645383835
- 272.5492742061615
- 295.6584829092026
- 266.5219302177429
- 240.50431609153748
- 236.99625599384308
- 211.5160014629364
- 212.18477201461792
- 227.73314726352692
- 200.87619519233704
- 217.62822937965393
- 191.92709946632385
- 175.41003382205963
- 177.45879483222961
- 181.26248514652252
- 159.94925928115845
- 187.55060905218124
- 171.78134310245514
- 196.27287077903748
- 180.16592007875443
- 160.61944603919983
- 181.0633289217949
- 196.75098729133606
- 183.50194221735
- 149.6920598745346
- 150.3337624669075
- 174.58629488945007
- 152.30579036474228
- 191.7603417634964
- 152.3410500884056
- 165.03138196468353
- 188.86065822839737
- 189.7722014784813
- 181.9630565047264
- 183.05792492628098
- 178.6997556090355
- 165.81879860162735
- 158.01331251859665
- 179.3146255016327
- 159.18912833929062
- 169.37550806999207
- 153.50957590341568
- 181.07572549581528
- 157.97384184598923
- 201.19762194156647
- 156.01247310638428
- 143.5905606150627
- 161.8854473233223
- 178.41649442911148
- 136.25332123041153
- 147.06206965446472
- 139.21447604894638
- 187.27957093715668
- 143.76767253875732
- 167.5015783905983
- 181.5340991616249
- 171.08891528844833
- 152.65678840875626
- 138.1713743209839
- 151.28446459770203
- 175.85110366344452
- 143.13105046749115
- 132.7611414194107
- 149.66616028547287
- 123.78847455978394
- 168.25306510925293
- 168.3292925953865
- 140.08307898044586
- 127.23093450069427
- 170.02257180213928
- 156.8308965563774
- 140.39012497663498
- 142.60574132204056
- 143.7137862443924
- 135.02628177404404
- 138.19517040252686
- 123.63476449251175
- 137.9826951622963
- 174.13842695951462
- 156.39629966020584
- 127.38725280761719
- 161.40829080343246
- 144.03676837682724
- 137.63414442539215
- 146.43477755784988
- 144.3342695236206
- 126.74199014902115
- 131.00303012132645
- 150.15149593353271
- 149.42806178331375
- 154.98741751909256
- 163.27034848928452
- 174.45709270238876
- 137.49060451984406
- 144.1748290657997
- 145.95476484298706
- 157.92568469047546
train_accuracy:
- 0.0
- 0.121
- 0.48
- 0.459
- 0.883
- 0.85
- 0.795
- 0.532
- 0.61
- 0.59
- 0.773
- 0.473
- 0.757
- 0.668
- 0.608
- 0.525
- 0.69
- 0.767
- 0.609
- 0.609
- 0.623
- 0.712
- 0.559
- 0.792
- 0.188
- 0.475
- 0.145
- 0.837
- 0.805
- 0.838
- 0.483
- 0.258
- 0.325
- 0.64
- 0.779
- 0.472
- 0.45
- 0.643
- 0.319
- 0.638
- 0.94
- 0.012
- 0.839
- 0.691
- 0.9
- 0.967
- 0.407
- 0.713
- 0.777
- 0.306
- 0.37
- 0.45
- 0.857
- 0.8
- 0.933
- 0.492
- 0.98
- 0.85
- 0.75
- 0.264
- 0.487
- 0.818
- 0.906
- 0.578
- 0.445
- 0.388
- 0.884
- 0.777
- 0.438
- 0.275
- 0.783
- 0.65
- 0.859
- 0.927
- 0.621
- 0.883
- 0.688
- 0.408
- 0.904
- 0.393
- 0.579
- 0.894
- 0.92
- 0.5
- 0.92
- 0.3
- 0.772
- 0.3
- 0.925
- 0.786
- 0.781
- 0.839
- 0.469
- 0.612
- 0.975
- 0.957
- 0.675
- 0.875
- 0.465
- 0.343
train_loss:
- 1.235
- 0.903
- 0.695
- 0.663
- 0.401
- 0.539
- 0.522
- 0.449
- 0.504
- 0.414
- 0.404
- 0.442
- 0.464
- 0.398
- 0.45
- 0.352
- 0.423
- 0.412
- 0.414
- 0.371
- 0.411
- 0.394
- 0.421
- 0.361
- 0.379
- 0.344
- 0.368
- 0.468
- 0.398
- 0.371
- 0.399
- 0.334
- 0.413
- 0.351
- 0.296
- 0.285
- 0.365
- 0.376
- 0.453
- 0.328
- 0.299
- 0.319
- 0.335
- 0.342
- 0.353
- 0.36
- 0.346
- 0.389
- 0.321
- 0.319
- 0.363
- 0.301
- 0.403
- 0.382
- 0.328
- 0.307
- 0.359
- 0.244
- 0.34
- 0.347
- 0.354
- 0.402
- 0.449
- 0.336
- 0.361
- 0.399
- 0.338
- 0.306
- 0.322
- 0.423
- 0.336
- 0.348
- 0.327
- 0.334
- 0.371
- 0.261
- 0.333
- 0.392
- 0.366
- 0.401
- 0.35
- 0.274
- 0.356
- 0.267
- 0.297
- 0.312
- 0.355
- 0.346
- 0.347
- 0.311
- 0.293
- 0.279
- 0.327
- 0.311
- 0.339
- 0.309
- 0.339
- 0.361
- 0.33
- 0.332
unequal: 1
verbose: 1
