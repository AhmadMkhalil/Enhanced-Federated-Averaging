avg_train_accuracy: 0.894
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.13670212765957446
- 0.246968085106383
- 0.33
- 0.38590425531914896
- 0.3753191489361702
- 0.47372340425531917
- 0.46430851063829787
- 0.4173404255319149
- 0.49872340425531914
- 0.5187234042553192
- 0.5722340425531914
- 0.5500531914893617
- 0.566063829787234
- 0.5677127659574468
- 0.5671276595744681
- 0.6497872340425532
- 0.5328723404255319
- 0.5639893617021277
- 0.6137765957446808
- 0.6318617021276596
- 0.6075531914893617
- 0.645
- 0.6287234042553191
- 0.6391489361702127
- 0.6039893617021277
- 0.5618617021276596
- 0.6252127659574468
- 0.6309574468085106
- 0.6755851063829788
- 0.6727127659574468
- 0.6496808510638298
- 0.5947872340425532
- 0.5898936170212766
- 0.6306382978723404
- 0.6625
- 0.6015957446808511
- 0.6317021276595745
- 0.6504787234042553
- 0.6439893617021276
- 0.6657446808510639
- 0.6475531914893617
- 0.625531914893617
- 0.5843617021276596
- 0.6108510638297873
- 0.6100531914893617
- 0.6361170212765958
- 0.6655851063829787
- 0.6926595744680851
- 0.6500531914893617
- 0.6732978723404255
- 0.6542553191489362
- 0.6501063829787234
- 0.6319148936170212
- 0.625531914893617
- 0.6773404255319149
- 0.6851063829787234
- 0.6697872340425531
- 0.648031914893617
- 0.6417553191489361
- 0.619095744680851
- 0.6823936170212765
- 0.6600531914893617
- 0.6692021276595744
- 0.6736702127659574
- 0.6420212765957447
- 0.6222872340425532
- 0.6349468085106383
- 0.6805851063829788
- 0.6444148936170213
- 0.6617021276595745
- 0.6607978723404255
- 0.6219148936170212
- 0.6556382978723404
- 0.6557978723404255
- 0.6243085106382978
- 0.6756382978723404
- 0.6422872340425532
- 0.6281382978723404
- 0.6667021276595745
- 0.6947872340425532
- 0.6546276595744681
- 0.6482446808510638
- 0.6395212765957446
- 0.6594148936170213
- 0.6822340425531915
- 0.661595744680851
- 0.6168617021276596
- 0.6626063829787234
- 0.6777659574468086
- 0.5993085106382978
- 0.7092553191489361
- 0.6793085106382979
- 0.6676595744680851
- 0.6807978723404255
- 0.7078723404255319
- 0.7137765957446809
- 0.7042021276595745
- 0.6642553191489362
- 0.693404255319149
- 0.6816489361702127
test_loss_list:
- 530.073303937912
- 448.37939953804016
- 382.03669571876526
- 347.2267849445343
- 328.76581478118896
- 267.4902913570404
- 246.7788348197937
- 274.2815001010895
- 233.17757952213287
- 213.36256337165833
- 220.87375855445862
- 203.33926796913147
- 191.6249120235443
- 180.7377496957779
- 192.09009510278702
- 158.5646372437477
- 204.61812257766724
- 175.24228012561798
- 164.85546326637268
- 170.49219131469727
- 165.57144117355347
- 156.57193505764008
- 154.00072354078293
- 146.70268100500107
- 162.0460097193718
- 181.86379432678223
- 162.25315076112747
- 156.00695753097534
- 145.3750976920128
- 138.70255208015442
- 145.92368483543396
- 174.7840206027031
- 178.9617019891739
- 157.81370162963867
- 146.15285873413086
- 188.08611458539963
- 151.0652250647545
- 150.1808795928955
- 149.52398014068604
- 137.79703217744827
- 150.99024361371994
- 163.165334045887
- 182.5840963125229
- 174.4146500825882
- 164.26938945055008
- 146.6372897028923
- 139.19797682762146
- 131.46368384361267
- 146.7142814397812
- 140.4090118408203
- 150.49239718914032
- 171.6219021677971
- 152.87293803691864
- 147.93836218118668
- 148.68018865585327
- 133.56396639347076
- 141.14472860097885
- 159.50003224611282
- 151.58034831285477
- 149.37931388616562
- 139.63749927282333
- 143.5053552389145
- 140.56258887052536
- 134.7461856007576
- 157.2383509874344
- 151.75581735372543
- 158.7974938750267
- 126.71177434921265
- 149.13549703359604
- 134.90111607313156
- 149.0859956741333
- 165.27798545360565
- 136.7214748263359
- 145.57899737358093
- 143.35162335634232
- 139.54804706573486
- 145.18857097625732
- 145.56747233867645
- 134.51911437511444
- 133.71249413490295
- 148.37688392400742
- 150.30734711885452
- 150.84360122680664
- 133.29502248764038
- 128.52726984024048
- 158.36908572912216
- 169.2270292043686
- 137.20087713003159
- 138.3964267373085
- 173.14505994319916
- 120.83959752321243
- 134.56948745250702
- 144.59255677461624
- 131.90692496299744
- 131.66256600618362
- 121.1756192445755
- 118.72283881902695
- 143.9035209417343
- 128.46331548690796
- 137.01183766126633
train_accuracy:
- 0.0
- 0.0
- 0.4
- 0.1
- 0.325
- 0.092
- 0.85
- 0.406
- 0.867
- 0.6
- 0.6
- 0.439
- 0.767
- 0.519
- 0.725
- 0.856
- 0.6
- 0.272
- 0.4
- 0.618
- 0.567
- 0.922
- 0.21
- 0.794
- 0.669
- 0.975
- 0.616
- 0.853
- 0.768
- 0.888
- 0.5
- 0.146
- 0.515
- 0.865
- 0.529
- 0.487
- 0.581
- 0.494
- 0.293
- 0.638
- 0.925
- 0.475
- 0.862
- 0.975
- 0.238
- 0.819
- 0.722
- 0.403
- 0.747
- 0.858
- 0.823
- 0.771
- 0.867
- 0.973
- 0.567
- 0.269
- 0.469
- 0.542
- 0.244
- 0.558
- 0.858
- 0.75
- 0.956
- 0.838
- 0.757
- 0.587
- 0.359
- 0.9
- 0.787
- 0.95
- 0.9
- 0.587
- 0.833
- 0.767
- 0.664
- 0.381
- 0.925
- 0.75
- 0.889
- 0.57
- 0.817
- 0.588
- 0.769
- 0.912
- 0.586
- 0.838
- 0.547
- 0.562
- 0.0
- 0.308
- 0.875
- 0.469
- 0.728
- 0.897
- 0.815
- 0.859
- 0.572
- 0.71
- 0.933
- 0.894
train_loss:
- 1.106
- 0.861
- 0.682
- 0.606
- 0.475
- 0.59
- 0.499
- 0.426
- 0.505
- 0.532
- 0.525
- 0.501
- 0.377
- 0.411
- 0.487
- 0.366
- 0.479
- 0.392
- 0.474
- 0.4
- 0.365
- 0.408
- 0.34
- 0.341
- 0.323
- 0.378
- 0.4
- 0.387
- 0.426
- 0.394
- 0.354
- 0.393
- 0.375
- 0.39
- 0.367
- 0.334
- 0.32
- 0.37
- 0.388
- 0.346
- 0.361
- 0.361
- 0.416
- 0.403
- 0.415
- 0.42
- 0.418
- 0.354
- 0.395
- 0.335
- 0.333
- 0.34
- 0.39
- 0.347
- 0.37
- 0.375
- 0.331
- 0.313
- 0.373
- 0.296
- 0.344
- 0.373
- 0.402
- 0.402
- 0.401
- 0.387
- 0.356
- 0.338
- 0.321
- 0.351
- 0.403
- 0.343
- 0.334
- 0.351
- 0.408
- 0.338
- 0.372
- 0.326
- 0.37
- 0.336
- 0.266
- 0.308
- 0.393
- 0.385
- 0.324
- 0.324
- 0.282
- 0.348
- 0.3
- 0.292
- 0.365
- 0.302
- 0.318
- 0.334
- 0.397
- 0.456
- 0.347
- 0.268
- 0.313
- 0.319
unequal: 1
verbose: 1
