avg_train_accuracy: 0.647
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.19819148936170214
- 0.26430851063829786
- 0.3274468085106383
- 0.33659574468085107
- 0.386063829787234
- 0.44803191489361704
- 0.4862234042553191
- 0.5012234042553192
- 0.48175531914893616
- 0.5245212765957447
- 0.5260638297872341
- 0.5382446808510638
- 0.5685106382978723
- 0.5957978723404256
- 0.5023404255319149
- 0.563936170212766
- 0.6212234042553192
- 0.5589893617021277
- 0.5205851063829787
- 0.6042553191489362
- 0.6346276595744681
- 0.6371808510638298
- 0.6587765957446808
- 0.5783510638297872
- 0.623031914893617
- 0.5996808510638297
- 0.6160638297872341
- 0.6240425531914894
- 0.6016489361702128
- 0.5829787234042553
- 0.6302127659574468
- 0.6580851063829787
- 0.6711702127659575
- 0.6329255319148936
- 0.5714893617021276
- 0.5388297872340425
- 0.6492021276595744
- 0.626968085106383
- 0.6372872340425532
- 0.602872340425532
- 0.6254787234042554
- 0.6007978723404256
- 0.6446808510638298
- 0.6352659574468085
- 0.6451595744680851
- 0.578936170212766
- 0.5888297872340426
- 0.633031914893617
- 0.6546808510638298
- 0.6490425531914894
- 0.6588297872340425
- 0.6723936170212766
- 0.6613297872340426
- 0.6548404255319149
- 0.6363297872340425
- 0.5975
- 0.6517553191489361
- 0.7053723404255319
- 0.6540425531914894
- 0.6729787234042554
- 0.6575531914893618
- 0.6301595744680851
- 0.6532446808510638
- 0.6631382978723405
- 0.6812765957446808
- 0.6623936170212766
- 0.6749468085106383
- 0.6667021276595745
- 0.6339893617021276
- 0.6492553191489362
- 0.6172340425531915
- 0.6627127659574468
- 0.6705319148936171
- 0.6561702127659574
- 0.6154787234042554
- 0.685372340425532
- 0.6965957446808511
- 0.6425531914893617
- 0.7114893617021276
- 0.6842021276595744
- 0.6658510638297872
- 0.6378191489361702
- 0.7136170212765958
- 0.645
- 0.6593085106382979
- 0.6717021276595745
- 0.651595744680851
- 0.6679787234042553
- 0.7067021276595745
- 0.699627659574468
- 0.6413297872340425
- 0.6698936170212766
- 0.6560106382978723
- 0.6898936170212766
- 0.6484042553191489
- 0.6824468085106383
- 0.6933510638297873
- 0.6936702127659574
- 0.6590425531914894
- 0.6329255319148936
test_loss_list:
- 523.7798573970795
- 446.597687959671
- 397.18078541755676
- 368.5894763469696
- 334.6019159555435
- 300.6995700597763
- 263.91958022117615
- 278.04401206970215
- 269.6542868614197
- 230.43121671676636
- 223.92937755584717
- 216.31505823135376
- 203.89443516731262
- 182.22498565912247
- 220.53457140922546
- 190.2126169204712
- 162.05605870485306
- 197.62746572494507
- 261.12906789779663
- 188.43913519382477
- 152.32428967952728
- 156.24199587106705
- 145.6106761097908
- 190.38926219940186
- 177.81100445985794
- 173.06901973485947
- 170.18991154432297
- 156.13697409629822
- 160.30413442850113
- 169.00080436468124
- 160.1627004146576
- 148.74563378095627
- 148.77788347005844
- 160.0174584388733
- 182.99425929784775
- 194.7451298236847
- 152.01603877544403
- 180.70460146665573
- 163.0924414396286
- 182.9295513033867
- 154.071462392807
- 180.7303351163864
- 159.1689230799675
- 167.62756443023682
- 148.2388806939125
- 176.83021491765976
- 185.2714427113533
- 152.30976712703705
- 150.69040149450302
- 146.8789006471634
- 155.43330651521683
- 139.93211770057678
- 144.08342134952545
- 164.5899342894554
- 158.9156854748726
- 175.89175736904144
- 144.50360637903214
- 131.9926499724388
- 146.21765971183777
- 138.74038934707642
- 150.93545520305634
- 163.85783356428146
- 157.73582082986832
- 141.07175594568253
- 130.84116113185883
- 141.14327532052994
- 137.70004379749298
- 145.11689138412476
- 149.95800203084946
- 153.8660374879837
- 157.36041831970215
- 142.2192027568817
- 136.3692368865013
- 145.33238697052002
- 163.2313715815544
- 134.39217871427536
- 130.34439945220947
- 147.9026386141777
- 121.31583201885223
- 131.59345483779907
- 145.10379165410995
- 153.34334129095078
- 127.10921901464462
- 154.97027903795242
- 139.33687949180603
- 136.13438653945923
- 145.32293462753296
- 149.77709060907364
- 135.91995584964752
- 129.22695422172546
- 177.45074731111526
- 132.03794968128204
- 149.58574378490448
- 125.59650772809982
- 142.05628907680511
- 139.58796083927155
- 129.96168917417526
- 129.10106426477432
- 137.46900063753128
- 163.15387922525406
train_accuracy:
- 0.042
- 0.145
- 0.317
- 0.038
- 0.203
- 0.321
- 0.517
- 0.567
- 0.925
- 0.514
- 0.582
- 0.763
- 0.806
- 0.359
- 0.867
- 0.48
- 0.721
- 0.075
- 0.217
- 0.429
- 0.79
- 0.513
- 0.363
- 0.017
- 0.825
- 0.98
- 0.434
- 0.269
- 0.792
- 0.894
- 0.686
- 0.632
- 0.722
- 0.458
- 1.0
- 0.05
- 0.65
- 0.229
- 0.625
- 0.02
- 0.775
- 0.95
- 0.85
- 0.975
- 0.838
- 0.644
- 0.95
- 0.45
- 0.619
- 0.867
- 0.821
- 0.4
- 0.517
- 0.688
- 0.695
- 0.417
- 0.503
- 0.93
- 0.35
- 0.92
- 0.574
- 0.96
- 0.927
- 0.628
- 0.644
- 0.533
- 0.771
- 0.631
- 0.814
- 0.97
- 0.774
- 0.808
- 0.528
- 0.721
- 0.897
- 0.847
- 0.957
- 0.59
- 0.18
- 0.881
- 0.33
- 0.774
- 0.785
- 0.554
- 0.295
- 0.792
- 0.173
- 0.833
- 0.5
- 0.173
- 0.628
- 0.438
- 0.336
- 0.786
- 0.879
- 0.87
- 0.931
- 0.747
- 0.858
- 0.647
train_loss:
- 1.174
- 0.674
- 0.614
- 0.574
- 0.608
- 0.544
- 0.38
- 0.377
- 0.455
- 0.44
- 0.453
- 0.481
- 0.451
- 0.442
- 0.399
- 0.428
- 0.427
- 0.419
- 0.342
- 0.379
- 0.461
- 0.368
- 0.368
- 0.35
- 0.306
- 0.343
- 0.365
- 0.398
- 0.4
- 0.318
- 0.269
- 0.393
- 0.415
- 0.383
- 0.287
- 0.373
- 0.334
- 0.269
- 0.377
- 0.306
- 0.369
- 0.367
- 0.395
- 0.283
- 0.336
- 0.401
- 0.364
- 0.403
- 0.35
- 0.306
- 0.304
- 0.37
- 0.337
- 0.397
- 0.314
- 0.32
- 0.339
- 0.319
- 0.247
- 0.381
- 0.338
- 0.301
- 0.288
- 0.388
- 0.384
- 0.484
- 0.327
- 0.336
- 0.35
- 0.336
- 0.269
- 0.312
- 0.289
- 0.304
- 0.317
- 0.336
- 0.234
- 0.365
- 0.355
- 0.339
- 0.364
- 0.363
- 0.323
- 0.35
- 0.342
- 0.321
- 0.354
- 0.28
- 0.234
- 0.314
- 0.311
- 0.286
- 0.273
- 0.274
- 0.349
- 0.356
- 0.378
- 0.312
- 0.304
- 0.257
unequal: 1
verbose: 1
