avg_train_accuracy: 0.05
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1148936170212766
- 0.23031914893617023
- 0.3002127659574468
- 0.41606382978723405
- 0.475
- 0.5029255319148936
- 0.44207446808510636
- 0.4823936170212766
- 0.4617553191489362
- 0.5329787234042553
- 0.5279255319148937
- 0.5672340425531915
- 0.5893085106382979
- 0.45611702127659576
- 0.5518617021276596
- 0.5131914893617021
- 0.5295744680851063
- 0.5471808510638297
- 0.5512234042553191
- 0.5400531914893617
- 0.5404255319148936
- 0.5776063829787234
- 0.6253191489361702
- 0.5298936170212766
- 0.626968085106383
- 0.578031914893617
- 0.5656914893617021
- 0.5596808510638298
- 0.616436170212766
- 0.6281914893617021
- 0.6222872340425532
- 0.6320212765957447
- 0.6022340425531915
- 0.612872340425532
- 0.6071276595744681
- 0.612659574468085
- 0.6497872340425532
- 0.6186170212765958
- 0.6134042553191489
- 0.6622872340425532
- 0.6259574468085106
- 0.6441489361702127
- 0.5870212765957447
- 0.6339893617021276
- 0.593404255319149
- 0.6469680851063829
- 0.6445212765957447
- 0.6540957446808511
- 0.6529787234042553
- 0.6273404255319149
- 0.6642021276595744
- 0.5982446808510639
- 0.646595744680851
- 0.6179787234042553
- 0.6135106382978723
- 0.6439893617021276
- 0.6487234042553192
- 0.6404255319148936
- 0.6742021276595744
- 0.6463829787234042
- 0.6306382978723404
- 0.6195744680851064
- 0.6247872340425532
- 0.6703191489361702
- 0.6419148936170213
- 0.681063829787234
- 0.6397340425531914
- 0.6441489361702127
- 0.678031914893617
- 0.6274468085106383
- 0.6407978723404255
- 0.6566489361702128
- 0.7012765957446808
- 0.6808510638297872
- 0.6584042553191489
- 0.6639893617021276
- 0.6353723404255319
- 0.6699468085106383
- 0.6559574468085106
- 0.6953191489361702
- 0.7022872340425532
- 0.6937765957446809
- 0.6830851063829787
- 0.7197340425531915
- 0.6985106382978723
- 0.6731914893617021
- 0.6874468085106383
- 0.6927659574468085
- 0.6632978723404256
- 0.6726595744680851
- 0.6967553191489362
- 0.6876595744680851
- 0.6629787234042553
- 0.6299468085106383
- 0.6686702127659574
- 0.6303191489361702
- 0.6313297872340425
- 0.7136702127659574
- 0.6331914893617021
- 0.6486170212765957
test_loss_list:
- 523.5193517208099
- 442.60090589523315
- 376.87174224853516
- 332.19977843761444
- 273.06139051914215
- 241.49927067756653
- 276.9120432138443
- 253.32041585445404
- 258.2662664651871
- 207.3975201845169
- 217.09490263462067
- 203.49203622341156
- 198.74088060855865
- 263.2613968849182
- 224.35185956954956
- 232.40975630283356
- 230.10039830207825
- 207.08483242988586
- 224.42986476421356
- 218.060769200325
- 211.508451461792
- 186.98677146434784
- 166.0018876194954
- 212.10497760772705
- 167.10782766342163
- 176.4553571343422
- 180.19331389665604
- 178.1421070098877
- 155.50576943159103
- 156.9662818312645
- 158.78625982999802
- 155.56844556331635
- 162.98842823505402
- 163.76834619045258
- 162.90236735343933
- 155.28425818681717
- 164.40273290872574
- 172.91324770450592
- 149.99189621210098
- 137.31209540367126
- 164.58586937189102
- 150.51223403215408
- 174.0283510684967
- 149.94005340337753
- 178.44881957769394
- 145.14484190940857
- 136.51584649085999
- 137.2792570590973
- 147.69308334589005
- 153.54936987161636
- 137.51210182905197
- 155.75697934627533
- 139.8380423784256
- 156.60363006591797
- 159.26515609025955
- 142.0884349346161
- 156.7681987285614
- 170.60648572444916
- 142.4289866089821
- 160.101542532444
- 143.33483225107193
- 149.8717011809349
- 149.23623824119568
- 142.50882649421692
- 144.01143074035645
- 130.59059047698975
- 143.22547334432602
- 147.38433516025543
- 129.97787564992905
- 150.94555568695068
- 149.76510924100876
- 150.82687771320343
- 121.11606711149216
- 138.48981058597565
- 134.53973215818405
- 151.582937002182
- 147.78128063678741
- 136.26792562007904
- 155.1460485458374
- 122.37108361721039
- 116.58920121192932
- 138.00897896289825
- 128.8927305340767
- 130.77258682250977
- 124.93932700157166
- 136.7310090661049
- 133.45839804410934
- 125.89960169792175
- 144.16164237260818
- 137.10906559228897
- 130.24690455198288
- 130.92202651500702
- 147.83276945352554
- 151.80013555288315
- 139.80024874210358
- 160.26712304353714
- 141.5077355504036
- 137.41872251033783
- 162.58553284406662
- 150.9657365679741
train_accuracy:
- 0.583
- 0.328
- 0.358
- 0.553
- 0.7
- 0.404
- 0.756
- 0.987
- 0.1
- 0.25
- 0.733
- 0.186
- 0.0
- 0.525
- 0.421
- 0.361
- 0.406
- 0.108
- 0.719
- 0.867
- 0.187
- 0.337
- 0.6
- 0.787
- 0.459
- 0.02
- 0.475
- 0.03
- 0.415
- 0.5
- 0.32
- 0.843
- 0.482
- 0.674
- 0.479
- 0.489
- 0.462
- 0.315
- 0.5
- 0.658
- 0.925
- 0.7
- 0.857
- 0.416
- 0.95
- 0.236
- 0.743
- 0.654
- 0.411
- 0.59
- 0.025
- 0.807
- 0.429
- 0.767
- 0.631
- 0.565
- 0.6
- 0.569
- 0.515
- 0.796
- 0.907
- 0.436
- 0.786
- 0.4
- 0.854
- 0.632
- 0.96
- 0.364
- 0.679
- 0.371
- 0.594
- 0.75
- 0.587
- 0.904
- 0.405
- 0.85
- 0.363
- 0.871
- 0.963
- 0.844
- 0.675
- 0.721
- 0.025
- 0.95
- 0.787
- 0.603
- 0.471
- 0.859
- 0.944
- 0.868
- 0.664
- 0.692
- 0.939
- 0.825
- 0.65
- 0.089
- 0.407
- 0.661
- 0.91
- 0.05
train_loss:
- 1.15
- 0.875
- 0.672
- 0.511
- 0.569
- 0.387
- 0.408
- 0.488
- 0.344
- 0.462
- 0.435
- 0.457
- 0.371
- 0.304
- 0.386
- 0.384
- 0.398
- 0.405
- 0.38
- 0.389
- 0.465
- 0.436
- 0.398
- 0.395
- 0.386
- 0.422
- 0.405
- 0.441
- 0.394
- 0.446
- 0.458
- 0.297
- 0.38
- 0.378
- 0.39
- 0.335
- 0.397
- 0.432
- 0.389
- 0.371
- 0.337
- 0.307
- 0.315
- 0.351
- 0.255
- 0.365
- 0.366
- 0.325
- 0.365
- 0.379
- 0.288
- 0.309
- 0.341
- 0.36
- 0.363
- 0.361
- 0.367
- 0.357
- 0.388
- 0.391
- 0.384
- 0.3
- 0.316
- 0.32
- 0.364
- 0.421
- 0.262
- 0.342
- 0.333
- 0.349
- 0.287
- 0.28
- 0.25
- 0.266
- 0.297
- 0.334
- 0.324
- 0.359
- 0.315
- 0.292
- 0.336
- 0.303
- 0.318
- 0.35
- 0.284
- 0.308
- 0.302
- 0.377
- 0.336
- 0.402
- 0.215
- 0.351
- 0.371
- 0.296
- 0.311
- 0.324
- 0.311
- 0.357
- 0.37
- 0.341
unequal: 1
verbose: 1
