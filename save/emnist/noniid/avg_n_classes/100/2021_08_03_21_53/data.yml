avg_train_accuracy: 0.914
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.15867021276595744
- 0.24436170212765956
- 0.24643617021276595
- 0.3376595744680851
- 0.4626063829787234
- 0.4932446808510638
- 0.4603191489361702
- 0.45345744680851063
- 0.5137234042553191
- 0.5206382978723404
- 0.5779787234042553
- 0.5139893617021276
- 0.5736170212765958
- 0.5546808510638298
- 0.5663297872340426
- 0.558404255319149
- 0.5844148936170213
- 0.5909042553191489
- 0.6071276595744681
- 0.601968085106383
- 0.5923936170212766
- 0.6098936170212766
- 0.5525531914893617
- 0.6073404255319149
- 0.5927127659574468
- 0.5927659574468085
- 0.6105851063829787
- 0.6183510638297872
- 0.6257446808510638
- 0.6473936170212766
- 0.6363297872340425
- 0.5893617021276596
- 0.6226063829787234
- 0.6522872340425532
- 0.6322340425531915
- 0.6220212765957447
- 0.614468085106383
- 0.6448404255319149
- 0.6561170212765958
- 0.6709574468085107
- 0.6581914893617021
- 0.638031914893617
- 0.7231382978723404
- 0.6386702127659575
- 0.6013829787234043
- 0.6161170212765957
- 0.6686702127659574
- 0.5715425531914894
- 0.675372340425532
- 0.636968085106383
- 0.6163297872340425
- 0.6495212765957447
- 0.5931914893617021
- 0.609468085106383
- 0.5701063829787234
- 0.6922340425531915
- 0.62
- 0.658936170212766
- 0.7001063829787234
- 0.6861170212765958
- 0.7248404255319149
- 0.6684042553191489
- 0.6454255319148936
- 0.6961702127659575
- 0.6814361702127659
- 0.6636702127659575
- 0.6552127659574468
- 0.6753191489361702
- 0.6954255319148936
- 0.6547872340425532
- 0.6362765957446809
- 0.6813829787234043
- 0.6833510638297873
- 0.6655319148936171
- 0.6533510638297872
- 0.6748404255319149
- 0.6948404255319149
- 0.6710106382978723
- 0.6781382978723405
- 0.7048936170212766
- 0.671595744680851
- 0.7259574468085106
- 0.6612234042553191
- 0.675531914893617
- 0.6851063829787234
- 0.6513297872340426
- 0.6694148936170212
- 0.6975
- 0.6698936170212766
- 0.6907978723404256
- 0.6023404255319149
- 0.6836702127659574
- 0.6936170212765957
- 0.6477127659574468
- 0.6484574468085106
- 0.596968085106383
- 0.6472872340425532
- 0.6360106382978723
- 0.6306914893617022
- 0.630904255319149
test_loss_list:
- 531.5142412185669
- 453.128427028656
- 401.17320680618286
- 347.8678833246231
- 275.3529027700424
- 251.86322855949402
- 275.38047993183136
- 244.64551103115082
- 218.8093295097351
- 215.99959754943848
- 194.07581758499146
- 207.77699208259583
- 190.05120027065277
- 212.27405071258545
- 199.20324218273163
- 193.6565864086151
- 190.37198567390442
- 183.7484454512596
- 176.0326094031334
- 184.04388374090195
- 176.42779886722565
- 159.07483541965485
- 193.34687328338623
- 163.6482271552086
- 178.28909248113632
- 170.93768280744553
- 166.8673493862152
- 157.86988323926926
- 163.9858636856079
- 144.37601655721664
- 147.60328263044357
- 178.41882836818695
- 164.83599615097046
- 159.27694636583328
- 147.95388621091843
- 150.30599749088287
- 164.20994228124619
- 145.28636121749878
- 139.60931777954102
- 159.71598213911057
- 145.69955003261566
- 155.02897584438324
- 128.40949022769928
- 153.1772856116295
- 177.23501133918762
- 161.61831277608871
- 145.00797498226166
- 186.21245294809341
- 139.59047269821167
- 150.92206984758377
- 163.74610823392868
- 145.40274113416672
- 178.58247488737106
- 166.31068575382233
- 171.59883612394333
- 130.1625126004219
- 170.3240106701851
- 147.48453223705292
- 126.59456944465637
- 129.46511828899384
- 118.18227761983871
- 151.27026742696762
- 154.13359117507935
- 133.82066160440445
- 136.8481389284134
- 137.08030378818512
- 141.8003282546997
- 136.71414577960968
- 127.47524470090866
- 142.88759952783585
- 161.48341631889343
- 135.76652425527573
- 135.67075562477112
- 142.35975563526154
- 148.31567120552063
- 140.04768651723862
- 136.297232568264
- 135.4212145805359
- 142.79978954792023
- 125.68820518255234
- 139.96016091108322
- 118.69135677814484
- 136.86957222223282
- 133.04710799455643
- 137.25548738241196
- 137.70657855272293
- 147.09834825992584
- 131.49665296077728
- 129.9525356888771
- 127.89326471090317
- 178.66166269779205
- 138.00194412469864
- 122.05962616205215
- 145.09153777360916
- 155.12883466482162
- 164.71254914999008
- 149.03373664617538
- 144.2535269856453
- 160.76123106479645
- 143.63911318778992
train_accuracy:
- 0.0
- 0.48
- 0.0
- 0.432
- 0.853
- 0.392
- 0.477
- 0.035
- 0.742
- 0.0
- 0.631
- 0.664
- 0.829
- 0.676
- 0.679
- 0.509
- 0.5
- 0.731
- 0.708
- 0.844
- 0.325
- 0.375
- 0.942
- 0.613
- 0.467
- 0.658
- 0.835
- 0.657
- 0.94
- 0.775
- 0.575
- 0.0
- 0.444
- 0.612
- 0.917
- 0.95
- 0.95
- 0.167
- 0.46
- 0.894
- 0.368
- 0.6
- 0.647
- 0.0
- 0.343
- 0.888
- 0.717
- 0.394
- 0.763
- 0.9
- 0.876
- 0.886
- 0.675
- 0.811
- 0.336
- 0.583
- 0.631
- 0.817
- 0.8
- 0.364
- 0.929
- 0.586
- 0.625
- 0.9
- 0.95
- 0.689
- 0.906
- 0.371
- 0.381
- 0.883
- 0.958
- 0.8
- 0.553
- 0.544
- 0.539
- 0.876
- 0.775
- 0.668
- 0.829
- 0.625
- 0.942
- 0.817
- 0.745
- 0.25
- 0.674
- 0.541
- 0.959
- 0.876
- 0.746
- 0.618
- 0.95
- 0.812
- 0.45
- 0.45
- 0.963
- 0.957
- 0.967
- 0.487
- 0.767
- 0.914
train_loss:
- 1.113
- 0.852
- 0.686
- 0.599
- 0.661
- 0.525
- 0.509
- 0.514
- 0.614
- 0.403
- 0.418
- 0.458
- 0.481
- 0.472
- 0.48
- 0.421
- 0.447
- 0.381
- 0.387
- 0.439
- 0.464
- 0.349
- 0.393
- 0.447
- 0.39
- 0.337
- 0.491
- 0.341
- 0.446
- 0.444
- 0.393
- 0.297
- 0.357
- 0.45
- 0.435
- 0.421
- 0.34
- 0.34
- 0.434
- 0.347
- 0.315
- 0.451
- 0.401
- 0.348
- 0.3
- 0.328
- 0.38
- 0.383
- 0.33
- 0.293
- 0.352
- 0.372
- 0.399
- 0.28
- 0.367
- 0.364
- 0.393
- 0.344
- 0.397
- 0.363
- 0.31
- 0.373
- 0.327
- 0.39
- 0.397
- 0.343
- 0.362
- 0.385
- 0.403
- 0.381
- 0.335
- 0.326
- 0.315
- 0.39
- 0.357
- 0.346
- 0.319
- 0.351
- 0.263
- 0.325
- 0.373
- 0.364
- 0.387
- 0.318
- 0.293
- 0.396
- 0.318
- 0.365
- 0.39
- 0.368
- 0.255
- 0.395
- 0.303
- 0.233
- 0.286
- 0.344
- 0.341
- 0.35
- 0.328
- 0.359
unequal: 1
verbose: 1
