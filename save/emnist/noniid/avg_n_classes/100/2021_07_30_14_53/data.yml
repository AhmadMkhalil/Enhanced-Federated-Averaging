avg_train_accuracy: 0.414
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.15069148936170212
- 0.18462765957446808
- 0.32351063829787235
- 0.4584042553191489
- 0.43101063829787234
- 0.4393085106382979
- 0.4765957446808511
- 0.4735106382978723
- 0.4518617021276596
- 0.5164893617021277
- 0.5160638297872341
- 0.523031914893617
- 0.5524468085106383
- 0.5459574468085107
- 0.5361170212765958
- 0.5894680851063829
- 0.5743617021276596
- 0.5953723404255319
- 0.6089361702127659
- 0.5721276595744681
- 0.5657978723404256
- 0.5041489361702127
- 0.5690425531914893
- 0.6215957446808511
- 0.6164893617021276
- 0.607872340425532
- 0.6247340425531915
- 0.6206382978723404
- 0.6297872340425532
- 0.5879255319148936
- 0.6262234042553192
- 0.6115425531914893
- 0.6019148936170213
- 0.5532446808510638
- 0.6253191489361702
- 0.584095744680851
- 0.6823936170212765
- 0.6537234042553192
- 0.6568617021276596
- 0.6161170212765957
- 0.6265425531914893
- 0.5816489361702127
- 0.6707446808510639
- 0.6589893617021276
- 0.6536170212765957
- 0.6012234042553192
- 0.6471808510638298
- 0.6306914893617022
- 0.6358510638297873
- 0.6590957446808511
- 0.5948936170212766
- 0.6152127659574468
- 0.6448404255319149
- 0.6337234042553191
- 0.6685106382978724
- 0.6601595744680852
- 0.6611170212765958
- 0.6437234042553192
- 0.6867021276595745
- 0.6613829787234042
- 0.634468085106383
- 0.6832446808510638
- 0.7003191489361702
- 0.6470744680851064
- 0.6398404255319149
- 0.6183510638297872
- 0.6017553191489362
- 0.6494148936170213
- 0.6283510638297872
- 0.6457446808510638
- 0.6342021276595745
- 0.6927659574468085
- 0.641436170212766
- 0.6617021276595745
- 0.7002127659574469
- 0.686063829787234
- 0.6613829787234042
- 0.6664361702127659
- 0.6456914893617022
- 0.6577127659574468
- 0.6631914893617021
- 0.6555851063829787
- 0.663031914893617
- 0.6189361702127659
- 0.6193617021276596
- 0.6820744680851064
- 0.7061170212765957
- 0.694627659574468
- 0.6886702127659574
- 0.6593617021276595
- 0.6525531914893618
- 0.678031914893617
- 0.6212765957446809
- 0.6785638297872341
- 0.695
- 0.6717553191489362
- 0.6534042553191489
- 0.7021808510638298
- 0.6540425531914894
- 0.6753191489361702
test_loss_list:
- 524.352775812149
- 460.54328322410583
- 366.05502557754517
- 294.28919064998627
- 288.73968517780304
- 275.5437914133072
- 250.09742069244385
- 239.8534678220749
- 247.42288637161255
- 249.9582177400589
- 243.8119821548462
- 216.71772408485413
- 202.787046790123
- 197.87012493610382
- 203.35651195049286
- 180.8568115234375
- 174.89672553539276
- 180.0297476053238
- 194.11032611131668
- 175.76458954811096
- 174.24127650260925
- 205.1003861427307
- 187.38634556531906
- 158.88962996006012
- 162.5111380815506
- 165.11980193853378
- 166.17692399024963
- 159.67081969976425
- 155.33782976865768
- 177.90506505966187
- 167.0296567082405
- 160.60867482423782
- 162.49744468927383
- 185.48266458511353
- 162.98599749803543
- 173.50461447238922
- 138.35483539104462
- 152.06803995370865
- 147.24940818548203
- 177.46194994449615
- 154.77427327632904
- 169.63436138629913
- 133.70156979560852
- 149.87816125154495
- 148.62524539232254
- 184.12366396188736
- 157.649458527565
- 162.9795168042183
- 163.35371100902557
- 151.67920118570328
- 185.21791619062424
- 150.49470233917236
- 143.6014860868454
- 166.30746912956238
- 133.63447380065918
- 144.38632613420486
- 145.79010289907455
- 146.05791234970093
- 132.63697576522827
- 142.70070964097977
- 144.00113463401794
- 126.99652427434921
- 128.58416438102722
- 144.67531245946884
- 142.4127289056778
- 156.31398618221283
- 173.12632757425308
- 156.07876390218735
- 159.8987352848053
- 136.93392914533615
- 154.92032659053802
- 127.69561564922333
- 153.83811831474304
- 146.38548028469086
- 128.0909544825554
- 133.23930674791336
- 129.02546852827072
- 136.7137195467949
- 160.7457835674286
- 151.34622144699097
- 147.43912678956985
- 143.6853887438774
- 136.1986060142517
- 159.30501252412796
- 170.87125426530838
- 145.80150151252747
- 123.58426016569138
- 132.67940258979797
- 126.08831512928009
- 151.4620047211647
- 156.5190950036049
- 126.75338608026505
- 153.65457493066788
- 127.70006501674652
- 131.78966909646988
- 152.11490815877914
- 148.5369814634323
- 116.53272658586502
- 150.05185651779175
- 139.45740896463394
train_accuracy:
- 0.073
- 0.045
- 0.52
- 0.4
- 0.327
- 0.289
- 0.835
- 0.0
- 0.861
- 0.829
- 0.864
- 0.336
- 0.31
- 0.594
- 0.117
- 0.83
- 0.809
- 0.614
- 0.97
- 0.93
- 0.97
- 0.342
- 0.361
- 0.446
- 0.653
- 0.862
- 0.7
- 0.486
- 0.74
- 0.914
- 0.208
- 0.625
- 0.762
- 0.212
- 0.91
- 0.657
- 0.65
- 0.312
- 0.764
- 0.467
- 0.591
- 0.85
- 0.355
- 0.843
- 0.503
- 0.0
- 0.442
- 0.765
- 0.412
- 0.197
- 0.05
- 0.814
- 0.875
- 0.444
- 0.603
- 0.786
- 0.835
- 0.696
- 0.833
- 0.91
- 0.219
- 0.69
- 0.781
- 0.325
- 0.5
- 0.779
- 0.658
- 0.933
- 0.777
- 0.817
- 0.81
- 0.585
- 0.564
- 0.908
- 0.82
- 0.8
- 0.413
- 0.85
- 0.547
- 0.73
- 0.609
- 0.923
- 0.94
- 0.542
- 0.478
- 0.611
- 0.906
- 0.707
- 0.892
- 0.818
- 0.837
- 0.865
- 0.87
- 0.9
- 0.661
- 0.89
- 0.8
- 0.13
- 0.483
- 0.414
train_loss:
- 1.084
- 0.867
- 0.684
- 0.642
- 0.588
- 0.483
- 0.508
- 0.376
- 0.504
- 0.375
- 0.446
- 0.491
- 0.419
- 0.393
- 0.46
- 0.374
- 0.365
- 0.42
- 0.349
- 0.424
- 0.382
- 0.381
- 0.391
- 0.39
- 0.433
- 0.298
- 0.313
- 0.36
- 0.447
- 0.383
- 0.332
- 0.434
- 0.381
- 0.381
- 0.316
- 0.301
- 0.409
- 0.31
- 0.322
- 0.316
- 0.276
- 0.326
- 0.332
- 0.448
- 0.397
- 0.276
- 0.289
- 0.308
- 0.287
- 0.369
- 0.32
- 0.35
- 0.365
- 0.296
- 0.298
- 0.353
- 0.333
- 0.273
- 0.363
- 0.356
- 0.323
- 0.374
- 0.346
- 0.348
- 0.376
- 0.267
- 0.369
- 0.317
- 0.317
- 0.318
- 0.326
- 0.384
- 0.283
- 0.328
- 0.369
- 0.294
- 0.361
- 0.301
- 0.3
- 0.297
- 0.338
- 0.304
- 0.279
- 0.382
- 0.271
- 0.346
- 0.334
- 0.381
- 0.358
- 0.279
- 0.3
- 0.343
- 0.364
- 0.318
- 0.363
- 0.228
- 0.337
- 0.237
- 0.293
- 0.33
unequal: 1
verbose: 1
