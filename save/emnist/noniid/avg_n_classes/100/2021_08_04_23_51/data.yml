avg_train_accuracy: 0.8
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.16691489361702128
- 0.2298936170212766
- 0.31622340425531914
- 0.3
- 0.4325
- 0.4575531914893617
- 0.5138297872340426
- 0.503031914893617
- 0.5320744680851064
- 0.5701063829787234
- 0.5717553191489362
- 0.5513297872340426
- 0.561595744680851
- 0.6196808510638298
- 0.5317021276595745
- 0.5668085106382978
- 0.5449468085106383
- 0.5828723404255319
- 0.5547340425531915
- 0.6196276595744681
- 0.6243085106382978
- 0.6038829787234042
- 0.6432978723404256
- 0.6252127659574468
- 0.5959574468085106
- 0.659468085106383
- 0.5699468085106383
- 0.6745212765957447
- 0.6669148936170213
- 0.6422872340425532
- 0.6101595744680851
- 0.6309574468085106
- 0.5623936170212765
- 0.6082446808510639
- 0.6478723404255319
- 0.6951595744680851
- 0.6603191489361702
- 0.653031914893617
- 0.5770744680851064
- 0.6474468085106383
- 0.6033510638297872
- 0.6792021276595744
- 0.6523404255319148
- 0.6545744680851063
- 0.6945212765957447
- 0.6763829787234042
- 0.666063829787234
- 0.6892021276595744
- 0.6701595744680852
- 0.6295744680851064
- 0.6817021276595745
- 0.68
- 0.6957446808510638
- 0.6473404255319148
- 0.6098404255319149
- 0.6502659574468085
- 0.6650531914893617
- 0.6320744680851064
- 0.6634574468085106
- 0.6617553191489361
- 0.6769148936170213
- 0.5564893617021277
- 0.6254787234042554
- 0.6843085106382979
- 0.6940425531914893
- 0.6436702127659575
- 0.6478191489361702
- 0.7018085106382979
- 0.6558510638297872
- 0.7033510638297872
- 0.6568617021276596
- 0.7051595744680851
- 0.6987234042553192
- 0.6852127659574468
- 0.6835638297872341
- 0.6584574468085106
- 0.6563297872340426
- 0.6592553191489362
- 0.651436170212766
- 0.6070212765957447
- 0.658936170212766
- 0.6226595744680851
- 0.6552127659574468
- 0.673031914893617
- 0.6676595744680851
- 0.6792021276595744
- 0.6777659574468086
- 0.6906382978723404
- 0.7106914893617021
- 0.6743085106382979
- 0.6753191489361702
- 0.6567021276595745
- 0.6675531914893617
- 0.7015425531914894
- 0.6942021276595745
- 0.7296276595744681
- 0.7036170212765958
- 0.7379787234042553
- 0.6810106382978723
- 0.7012234042553191
test_loss_list:
- 533.8316612243652
- 455.14249300956726
- 392.5321273803711
- 395.58711671829224
- 314.2767504453659
- 269.4843202829361
- 242.1144621372223
- 233.54426527023315
- 223.95384848117828
- 197.44078600406647
- 204.42849826812744
- 204.82228875160217
- 190.2768919467926
- 176.25469940900803
- 211.78765630722046
- 199.55301928520203
- 196.65157747268677
- 183.7234451174736
- 188.88910788297653
- 164.85589069128036
- 164.9477026462555
- 172.50457817316055
- 154.65733712911606
- 156.43978589773178
- 179.46784406900406
- 152.0901522040367
- 188.37521600723267
- 143.0303157567978
- 154.5188152194023
- 150.7443883419037
- 164.66823065280914
- 161.65222281217575
- 185.9225790500641
- 161.75915616750717
- 154.4394857287407
- 144.28249752521515
- 154.2498800754547
- 146.39607733488083
- 172.37159341573715
- 151.13093268871307
- 175.9246118068695
- 143.52745187282562
- 145.63275718688965
- 142.27621990442276
- 133.51793044805527
- 137.56444853544235
- 160.03258126974106
- 132.9633863568306
- 141.5976658463478
- 161.07367706298828
- 139.0854441523552
- 134.87431573867798
- 143.10087251663208
- 155.30265587568283
- 168.431310236454
- 153.98050677776337
- 140.92454200983047
- 157.02946609258652
- 148.51393568515778
- 144.88759917020798
- 140.2146697640419
- 193.77600240707397
- 158.57650023698807
- 138.68088376522064
- 130.05258303880692
- 154.4328449368477
- 151.07042783498764
- 127.84339964389801
- 144.13904738426208
- 132.458675801754
- 154.749734044075
- 123.23811203241348
- 132.77235651016235
- 140.62364107370377
- 133.15022844076157
- 140.58811062574387
- 148.31064623594284
- 142.57553231716156
- 150.22938388586044
- 162.22888225317
- 155.89911031723022
- 175.93509596586227
- 147.00822669267654
- 137.26932483911514
- 145.07868844270706
- 140.4248612523079
- 139.15889233350754
- 133.77976667881012
- 117.06300741434097
- 131.63017958402634
- 139.75826966762543
- 158.23711693286896
- 141.41661256551743
- 126.8899610042572
- 129.8958643078804
- 113.0096617937088
- 128.76689141988754
- 111.9166808128357
- 140.2424060702324
- 129.84545367956161
train_accuracy:
- 0.283
- 0.0
- 0.45
- 0.0
- 0.425
- 0.327
- 0.716
- 0.306
- 0.883
- 0.359
- 0.481
- 0.388
- 0.556
- 0.834
- 0.983
- 0.777
- 0.547
- 0.645
- 0.56
- 0.4
- 0.781
- 0.142
- 0.581
- 0.812
- 0.625
- 0.691
- 0.137
- 0.831
- 0.846
- 0.55
- 0.795
- 0.536
- 0.183
- 0.944
- 0.963
- 0.606
- 0.487
- 0.7
- 0.575
- 0.9
- 0.8
- 0.587
- 0.6
- 0.719
- 0.954
- 0.443
- 0.8
- 0.787
- 0.617
- 0.469
- 0.8
- 0.405
- 0.784
- 0.609
- 0.956
- 0.883
- 0.067
- 0.558
- 0.943
- 0.888
- 0.575
- 0.85
- 0.938
- 0.505
- 0.936
- 0.513
- 0.736
- 0.771
- 0.827
- 0.83
- 0.737
- 0.758
- 0.858
- 0.456
- 0.11
- 0.944
- 0.653
- 0.622
- 0.896
- 0.94
- 0.796
- 0.787
- 0.579
- 0.674
- 0.875
- 0.975
- 0.487
- 0.768
- 0.707
- 0.95
- 0.873
- 0.209
- 0.657
- 0.95
- 0.8
- 0.888
- 0.731
- 0.919
- 0.431
- 0.8
train_loss:
- 1.102
- 0.761
- 0.69
- 0.615
- 0.585
- 0.537
- 0.454
- 0.534
- 0.503
- 0.436
- 0.472
- 0.474
- 0.468
- 0.49
- 0.38
- 0.459
- 0.416
- 0.462
- 0.451
- 0.466
- 0.48
- 0.318
- 0.459
- 0.358
- 0.346
- 0.408
- 0.425
- 0.448
- 0.38
- 0.421
- 0.448
- 0.386
- 0.355
- 0.383
- 0.391
- 0.359
- 0.343
- 0.39
- 0.338
- 0.404
- 0.34
- 0.362
- 0.295
- 0.428
- 0.337
- 0.406
- 0.331
- 0.45
- 0.409
- 0.348
- 0.407
- 0.356
- 0.312
- 0.364
- 0.367
- 0.297
- 0.337
- 0.379
- 0.44
- 0.319
- 0.396
- 0.377
- 0.297
- 0.367
- 0.371
- 0.423
- 0.37
- 0.337
- 0.335
- 0.311
- 0.357
- 0.404
- 0.342
- 0.358
- 0.373
- 0.336
- 0.347
- 0.304
- 0.259
- 0.363
- 0.308
- 0.284
- 0.317
- 0.382
- 0.326
- 0.352
- 0.343
- 0.369
- 0.308
- 0.333
- 0.322
- 0.315
- 0.286
- 0.333
- 0.324
- 0.351
- 0.311
- 0.38
- 0.307
- 0.366
unequal: 1
verbose: 1
