avg_train_accuracy: 0.65
avg_train_loss: 0.003
avg_type: avg_n_classes
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.1829255319148936
- 0.21595744680851064
- 0.3467021276595745
- 0.3158510638297872
- 0.363031914893617
- 0.46867021276595744
- 0.4770744680851064
- 0.5422340425531915
- 0.5034574468085107
- 0.5562234042553191
- 0.5142021276595745
- 0.5564893617021277
- 0.5390425531914894
- 0.591968085106383
- 0.5497340425531915
- 0.5367553191489361
- 0.508031914893617
- 0.5198404255319149
- 0.6497340425531914
- 0.5805851063829788
- 0.6015957446808511
- 0.5614361702127659
- 0.6313829787234042
- 0.6065957446808511
- 0.5748936170212766
- 0.5429255319148936
- 0.6224468085106383
- 0.6119148936170212
- 0.6269148936170212
- 0.6092021276595745
- 0.6323936170212766
- 0.5820744680851064
- 0.6425531914893617
- 0.6173936170212766
- 0.5926595744680851
- 0.625
- 0.6470212765957447
- 0.684468085106383
- 0.678936170212766
- 0.6491489361702127
- 0.631436170212766
- 0.6512234042553191
- 0.6688297872340425
- 0.6490957446808511
- 0.6320744680851064
- 0.6426063829787234
- 0.6570212765957447
- 0.6637765957446808
- 0.5802659574468085
- 0.6107446808510638
- 0.6301595744680851
- 0.5924468085106382
- 0.6837765957446809
- 0.6604787234042553
- 0.7038297872340425
- 0.6148404255319149
- 0.6686170212765957
- 0.6263297872340425
- 0.6690425531914893
- 0.6004787234042553
- 0.646436170212766
- 0.5652127659574468
- 0.6964893617021276
- 0.6310638297872341
- 0.6196276595744681
- 0.6586702127659575
- 0.6182446808510639
- 0.6793085106382979
- 0.5980851063829787
- 0.6478191489361702
- 0.6661702127659574
- 0.6857978723404256
- 0.6248404255319149
- 0.6714361702127659
- 0.6621276595744681
- 0.6450531914893617
- 0.6759042553191489
- 0.6334042553191489
- 0.666595744680851
- 0.6303191489361702
- 0.6382446808510638
- 0.6311702127659574
- 0.6472340425531915
- 0.678031914893617
- 0.6742553191489362
- 0.6795212765957447
- 0.6418617021276596
- 0.6700531914893617
- 0.6923404255319149
- 0.6349468085106383
- 0.6488829787234043
- 0.6175
- 0.6546276595744681
- 0.6643617021276595
- 0.6896808510638298
- 0.6845744680851064
- 0.6571808510638298
- 0.6785638297872341
- 0.6271808510638298
- 0.6239361702127659
test_loss_list:
- 524.9212868213654
- 466.80894231796265
- 371.8912134170532
- 353.127690076828
- 323.73957550525665
- 260.26650536060333
- 242.05717766284943
- 220.40162813663483
- 230.6935591697693
- 208.02751886844635
- 218.81702744960785
- 204.56452929973602
- 199.6320939064026
- 180.12905836105347
- 205.49515295028687
- 200.91697597503662
- 206.01196920871735
- 214.2445774078369
- 164.28014850616455
- 176.4791004061699
- 185.18606054782867
- 183.9416806101799
- 160.73036229610443
- 168.0734925866127
- 184.2129232287407
- 202.21925455331802
- 170.6819058060646
- 175.6658753156662
- 168.98556977510452
- 168.04448974132538
- 165.7173873782158
- 178.6673642396927
- 147.41856741905212
- 152.0778176188469
- 183.7677235007286
- 156.45755398273468
- 145.7142979502678
- 132.89170563220978
- 138.74529039859772
- 144.63482904434204
- 153.70931839942932
- 145.33849489688873
- 144.47297072410583
- 158.05549031496048
- 152.9340764284134
- 158.8133551478386
- 152.66967648267746
- 156.6997975707054
- 170.61101895570755
- 162.83119708299637
- 158.27571660280228
- 169.7542209625244
- 132.77254623174667
- 139.0268920660019
- 131.5261544585228
- 166.7290083169937
- 147.07292330265045
- 156.59179681539536
- 143.0672840476036
- 166.48111271858215
- 156.86416977643967
- 196.33642947673798
- 139.21512466669083
- 162.98336899280548
- 154.8489454984665
- 144.9639003276825
- 154.22102212905884
- 139.14824587106705
- 159.72081154584885
- 144.60042756795883
- 134.39861392974854
- 136.12663727998734
- 153.87422680854797
- 146.05105406045914
- 146.2398020029068
- 152.49742430448532
- 137.91543793678284
- 160.8365180492401
- 133.8830759525299
- 156.8297882080078
- 141.4611341357231
- 141.19381195306778
- 153.90453785657883
- 139.2959879040718
- 137.07345736026764
- 137.11024051904678
- 161.8563915491104
- 156.47549879550934
- 124.51635652780533
- 140.37259954214096
- 149.69079196453094
- 157.5113674402237
- 154.6797760128975
- 135.60928267240524
- 137.1688449382782
- 131.82411843538284
- 152.71807777881622
- 127.34057712554932
- 146.9890974164009
- 151.88179296255112
train_accuracy:
- 0.0
- 0.767
- 0.071
- 0.257
- 0.883
- 0.05
- 0.5
- 0.483
- 0.933
- 0.458
- 0.1
- 0.632
- 0.956
- 0.797
- 0.236
- 0.87
- 0.279
- 0.833
- 0.847
- 0.379
- 0.497
- 0.864
- 0.79
- 0.844
- 0.1
- 0.97
- 0.858
- 0.833
- 0.933
- 0.614
- 0.707
- 0.697
- 0.378
- 0.767
- 0.914
- 0.589
- 0.775
- 0.479
- 0.722
- 0.758
- 0.642
- 0.847
- 0.582
- 0.768
- 0.967
- 0.394
- 0.915
- 0.878
- 0.914
- 0.436
- 0.567
- 0.682
- 0.825
- 0.657
- 0.955
- 0.0
- 0.693
- 0.417
- 0.708
- 0.582
- 0.59
- 0.355
- 0.707
- 0.929
- 0.9
- 0.664
- 0.05
- 0.229
- 0.88
- 0.95
- 0.84
- 0.364
- 0.835
- 0.875
- 0.489
- 0.838
- 0.929
- 0.585
- 0.88
- 0.164
- 0.531
- 0.95
- 0.625
- 0.777
- 0.884
- 0.685
- 0.207
- 0.79
- 0.554
- 0.31
- 0.97
- 0.907
- 0.785
- 0.958
- 0.709
- 0.503
- 0.527
- 0.258
- 0.275
- 0.65
train_loss:
- 1.068
- 0.769
- 0.727
- 0.507
- 0.622
- 0.52
- 0.509
- 0.449
- 0.449
- 0.51
- 0.419
- 0.422
- 0.408
- 0.404
- 0.367
- 0.412
- 0.465
- 0.389
- 0.405
- 0.381
- 0.409
- 0.382
- 0.427
- 0.381
- 0.341
- 0.397
- 0.352
- 0.355
- 0.36
- 0.358
- 0.391
- 0.441
- 0.402
- 0.305
- 0.347
- 0.318
- 0.297
- 0.367
- 0.394
- 0.323
- 0.276
- 0.349
- 0.361
- 0.385
- 0.314
- 0.29
- 0.31
- 0.295
- 0.352
- 0.383
- 0.332
- 0.339
- 0.306
- 0.264
- 0.338
- 0.353
- 0.298
- 0.36
- 0.286
- 0.38
- 0.316
- 0.359
- 0.306
- 0.361
- 0.315
- 0.329
- 0.31
- 0.359
- 0.32
- 0.366
- 0.406
- 0.297
- 0.335
- 0.378
- 0.339
- 0.332
- 0.291
- 0.284
- 0.402
- 0.335
- 0.386
- 0.298
- 0.264
- 0.372
- 0.33
- 0.3
- 0.3
- 0.233
- 0.333
- 0.335
- 0.363
- 0.347
- 0.268
- 0.401
- 0.369
- 0.346
- 0.257
- 0.339
- 0.315
- 0.28
unequal: 1
verbose: 1
