avg_train_accuracy: 0.794
avg_train_loss: 0.004
avg_type: avg_n_classes
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.14446808510638298
- 0.27122340425531916
- 0.33154255319148934
- 0.31186170212765957
- 0.4392553191489362
- 0.5063297872340425
- 0.44388297872340426
- 0.5310106382978723
- 0.4958510638297872
- 0.5176595744680851
- 0.5661170212765958
- 0.5269680851063829
- 0.5387765957446808
- 0.5658510638297872
- 0.6019148936170213
- 0.5901595744680851
- 0.5752127659574469
- 0.5327127659574468
- 0.5643085106382979
- 0.5981382978723404
- 0.6219148936170212
- 0.6423936170212766
- 0.6137765957446808
- 0.5896808510638298
- 0.6192553191489362
- 0.5667021276595745
- 0.6029787234042553
- 0.6138297872340426
- 0.6145744680851064
- 0.6350531914893617
- 0.6337234042553191
- 0.5659042553191489
- 0.5905851063829787
- 0.6329255319148936
- 0.6119148936170212
- 0.6697340425531915
- 0.6308510638297873
- 0.5821808510638298
- 0.6456382978723404
- 0.6333510638297872
- 0.620531914893617
- 0.635531914893617
- 0.6707446808510639
- 0.610531914893617
- 0.6488829787234043
- 0.6257978723404255
- 0.6535106382978724
- 0.6526595744680851
- 0.6624468085106383
- 0.635904255319149
- 0.6287765957446808
- 0.6698936170212766
- 0.6539893617021276
- 0.6211702127659574
- 0.6586702127659575
- 0.6772340425531915
- 0.6581914893617021
- 0.660372340425532
- 0.6293085106382978
- 0.6543085106382979
- 0.6788297872340425
- 0.6601063829787234
- 0.6019148936170213
- 0.6469680851063829
- 0.6462765957446809
- 0.6298936170212766
- 0.6484042553191489
- 0.6460638297872341
- 0.6278191489361702
- 0.6417021276595745
- 0.6606382978723404
- 0.6501595744680851
- 0.6422872340425532
- 0.6434574468085107
- 0.6307978723404255
- 0.6672872340425532
- 0.6642021276595744
- 0.6807978723404255
- 0.650904255319149
- 0.6312765957446809
- 0.6548404255319149
- 0.6003723404255319
- 0.7029255319148936
- 0.726436170212766
- 0.6866489361702127
- 0.726063829787234
- 0.6768085106382978
- 0.6837234042553192
- 0.6315957446808511
- 0.6512234042553191
- 0.6761702127659575
- 0.6510106382978723
- 0.6982446808510638
- 0.6671808510638297
- 0.6424468085106383
- 0.6651595744680852
- 0.6860106382978723
- 0.6562234042553191
- 0.7032446808510638
- 0.6749468085106383
test_loss_list:
- 522.7278034687042
- 428.5093867778778
- 364.4229760169983
- 366.3295578956604
- 292.79884791374207
- 243.19966161251068
- 268.3540326356888
- 237.91708183288574
- 241.2951933145523
- 226.34335780143738
- 207.05780839920044
- 211.46209573745728
- 202.2324434518814
- 192.0651603937149
- 175.0272029042244
- 185.6832573413849
- 184.61287814378738
- 207.15818572044373
- 202.87866485118866
- 177.46282821893692
- 178.81943833827972
- 161.7784445285797
- 162.4679434299469
- 176.86003267765045
- 158.85099828243256
- 173.5904089808464
- 165.44365066289902
- 169.4673907160759
- 153.55799317359924
- 149.17198675870895
- 166.72601348161697
- 180.7715595960617
- 186.4782167673111
- 163.17778980731964
- 169.8913972377777
- 136.80182886123657
- 145.33814752101898
- 174.88036799430847
- 157.31214374303818
- 164.4478011727333
- 171.09757924079895
- 158.73379385471344
- 137.900777220726
- 165.922414124012
- 143.84198713302612
- 151.78093069791794
- 147.80633556842804
- 140.22538977861404
- 131.98456799983978
- 151.17595785856247
- 168.2079409956932
- 136.04296404123306
- 153.14406615495682
- 170.68322712183
- 147.53981268405914
- 137.9743066430092
- 136.82595098018646
- 136.85632365942
- 153.07801735401154
- 142.0394578576088
- 141.072316467762
- 143.86415392160416
- 166.3123295903206
- 154.1390323638916
- 161.21126943826675
- 177.21854788064957
- 154.55059468746185
- 145.57757198810577
- 163.18715119361877
- 142.22432881593704
- 142.12317830324173
- 152.96059209108353
- 157.3701400756836
- 162.6306313276291
- 149.3823070526123
- 134.08273416757584
- 145.06060469150543
- 129.72367906570435
- 138.67115062475204
- 150.540909409523
- 143.14845484495163
- 157.47622215747833
- 122.58090108633041
- 117.23064315319061
- 127.22864371538162
- 111.6663007736206
- 145.59156441688538
- 136.30422884225845
- 145.9163001179695
- 140.62835907936096
- 135.25099861621857
- 152.48522394895554
- 128.82854598760605
- 137.4008578658104
- 146.9321158528328
- 135.60864120721817
- 133.3930681347847
- 129.4913701415062
- 117.2361911535263
- 132.5645118355751
train_accuracy:
- 0.175
- 0.472
- 0.113
- 0.037
- 0.475
- 0.025
- 0.386
- 0.606
- 0.6
- 0.433
- 0.875
- 0.179
- 0.39
- 0.663
- 0.133
- 0.771
- 0.179
- 0.025
- 0.225
- 0.8
- 0.531
- 0.567
- 0.289
- 0.111
- 0.754
- 0.219
- 0.86
- 0.565
- 0.439
- 0.505
- 0.914
- 0.475
- 0.921
- 0.383
- 0.583
- 0.171
- 0.83
- 0.821
- 0.783
- 0.35
- 0.975
- 0.7
- 0.9
- 0.889
- 0.65
- 0.454
- 0.3
- 0.603
- 0.638
- 0.95
- 0.492
- 0.767
- 0.462
- 0.603
- 0.708
- 0.435
- 0.342
- 0.858
- 0.797
- 0.692
- 0.89
- 0.721
- 0.675
- 0.883
- 0.527
- 0.4
- 0.854
- 0.775
- 0.458
- 0.867
- 0.718
- 0.605
- 0.613
- 0.417
- 0.883
- 0.63
- 0.487
- 0.632
- 0.45
- 0.687
- 0.529
- 0.638
- 0.703
- 0.688
- 0.817
- 0.605
- 0.814
- 0.638
- 0.356
- 0.75
- 0.506
- 0.718
- 0.779
- 0.835
- 0.818
- 1.0
- 0.79
- 0.6
- 0.94
- 0.794
train_loss:
- 1.175
- 0.779
- 0.705
- 0.52
- 0.638
- 0.553
- 0.452
- 0.446
- 0.374
- 0.363
- 0.488
- 0.531
- 0.305
- 0.47
- 0.413
- 0.349
- 0.435
- 0.49
- 0.423
- 0.38
- 0.372
- 0.418
- 0.394
- 0.482
- 0.287
- 0.387
- 0.358
- 0.421
- 0.435
- 0.394
- 0.337
- 0.38
- 0.359
- 0.284
- 0.278
- 0.382
- 0.337
- 0.399
- 0.396
- 0.388
- 0.366
- 0.41
- 0.336
- 0.324
- 0.34
- 0.277
- 0.345
- 0.334
- 0.325
- 0.335
- 0.373
- 0.41
- 0.428
- 0.371
- 0.3
- 0.341
- 0.38
- 0.396
- 0.34
- 0.394
- 0.337
- 0.338
- 0.356
- 0.328
- 0.281
- 0.263
- 0.398
- 0.316
- 0.292
- 0.33
- 0.363
- 0.368
- 0.372
- 0.272
- 0.3
- 0.333
- 0.353
- 0.393
- 0.319
- 0.369
- 0.381
- 0.316
- 0.373
- 0.36
- 0.332
- 0.332
- 0.337
- 0.325
- 0.31
- 0.344
- 0.369
- 0.318
- 0.325
- 0.302
- 0.282
- 0.291
- 0.284
- 0.317
- 0.268
- 0.408
unequal: 1
verbose: 1
