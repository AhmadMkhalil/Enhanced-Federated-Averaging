avg_train_accuracy: 0.46
avg_train_loss: 0.004
avg_type: avg
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.11079787234042553
- 0.2372872340425532
- 0.3007446808510638
- 0.3424468085106383
- 0.3556382978723404
- 0.32515957446808513
- 0.45909574468085107
- 0.39914893617021274
- 0.48340425531914893
- 0.4868085106382979
- 0.502127659574468
- 0.5293085106382979
- 0.49617021276595746
- 0.5006382978723404
- 0.5308510638297872
- 0.5162234042553191
- 0.5731914893617022
- 0.5637765957446809
- 0.5086170212765957
- 0.5859574468085106
- 0.5721808510638298
- 0.5572872340425532
- 0.5537765957446809
- 0.5954255319148937
- 0.586436170212766
- 0.5826063829787234
- 0.6779787234042554
- 0.6623404255319149
- 0.6079255319148936
- 0.6610106382978723
- 0.6257978723404255
- 0.6203723404255319
- 0.6594148936170213
- 0.6344148936170213
- 0.6394148936170213
- 0.6263297872340425
- 0.6620744680851064
- 0.6210106382978723
- 0.6539893617021276
- 0.6340957446808511
- 0.6172340425531915
- 0.6511170212765958
- 0.6000531914893616
- 0.6673404255319149
- 0.641595744680851
- 0.6030851063829787
- 0.6272872340425532
- 0.6645744680851063
- 0.6586170212765957
- 0.6142021276595745
- 0.6902127659574468
- 0.6573404255319149
- 0.6247872340425532
- 0.633031914893617
- 0.6608510638297872
- 0.641595744680851
- 0.6419148936170213
- 0.641595744680851
- 0.6256914893617022
- 0.610531914893617
- 0.6284042553191489
- 0.6712234042553191
- 0.6670212765957447
- 0.6876063829787235
- 0.6798404255319149
- 0.6966489361702127
- 0.6861170212765958
- 0.6651595744680852
- 0.626436170212766
- 0.6870744680851064
- 0.6745744680851063
- 0.6939893617021277
- 0.6727127659574468
- 0.6571808510638298
- 0.6084574468085107
- 0.6310638297872341
- 0.6754787234042553
- 0.7071808510638298
- 0.6570212765957447
- 0.6629255319148936
- 0.6832978723404255
- 0.6637234042553192
- 0.6558510638297872
- 0.6666489361702128
- 0.6633510638297873
- 0.6516489361702128
- 0.6618617021276596
- 0.6754255319148936
- 0.6665425531914894
- 0.6582446808510638
- 0.6306382978723404
- 0.6317021276595745
- 0.6760106382978723
- 0.6633510638297873
- 0.6854255319148936
- 0.7290425531914894
- 0.6747340425531915
- 0.713404255319149
- 0.7083510638297872
- 0.6795212765957447
test_loss_list:
- 538.3030409812927
- 454.58913397789
- 387.10697841644287
- 345.65647435188293
- 327.81499564647675
- 338.8880168199539
- 267.5660492181778
- 270.08404219150543
- 243.61905789375305
- 249.14085173606873
- 216.78039705753326
- 218.08225452899933
- 210.78410983085632
- 217.95205998420715
- 204.78133368492126
- 212.39639675617218
- 194.3617401123047
- 189.74124908447266
- 207.5992181301117
- 181.709015250206
- 188.4676433801651
- 210.08725881576538
- 196.83042764663696
- 165.9775106906891
- 172.56240981817245
- 182.96177679300308
- 150.4707751274109
- 150.17691713571548
- 162.93444335460663
- 144.3395358324051
- 156.38353037834167
- 167.93780767917633
- 152.58645141124725
- 159.48309761285782
- 160.0497220158577
- 160.97669178247452
- 140.39165645837784
- 150.08283334970474
- 145.0837423801422
- 170.88972359895706
- 178.3288386464119
- 146.86077070236206
- 159.16885441541672
- 142.65991020202637
- 142.9037185907364
- 161.72041898965836
- 154.0414478778839
- 135.9166339635849
- 138.8216552734375
- 169.4305945634842
- 133.47353345155716
- 148.79805892705917
- 152.55923718214035
- 147.80178147554398
- 149.1253224015236
- 149.81877899169922
- 153.24539697170258
- 146.0390266776085
- 152.17151820659637
- 153.9671751856804
- 143.75485903024673
- 139.14075833559036
- 152.51672106981277
- 130.5765643119812
- 137.02696800231934
- 122.27364355325699
- 133.5825333595276
- 137.76403504610062
- 155.8326739668846
- 132.2572511434555
- 131.98312109708786
- 126.96553963422775
- 127.02144360542297
- 136.8922816514969
- 155.59114396572113
- 146.56820183992386
- 134.4450200200081
- 119.58215308189392
- 139.47052866220474
- 133.56966853141785
- 132.31691884994507
- 132.1501561999321
- 133.39046442508698
- 135.5456560254097
- 133.6543036699295
- 155.51385217905045
- 132.79075932502747
- 139.1163588166237
- 135.98777264356613
- 141.5162888765335
- 151.00541245937347
- 165.2995920777321
- 128.37309938669205
- 138.64778059720993
- 128.4173725247383
- 114.10580855607986
- 138.84215474128723
- 129.23324447870255
- 125.82086008787155
- 133.07713508605957
train_accuracy:
- 0.162
- 0.0
- 0.0
- 0.253
- 0.045
- 0.05
- 0.99
- 0.204
- 0.919
- 0.279
- 0.925
- 0.45
- 0.933
- 0.428
- 0.312
- 0.417
- 0.831
- 0.64
- 0.0
- 0.424
- 0.647
- 0.858
- 0.741
- 0.0
- 0.611
- 0.763
- 0.5
- 0.787
- 0.629
- 0.723
- 0.1
- 0.464
- 0.7
- 0.833
- 0.54
- 0.685
- 0.838
- 0.338
- 0.817
- 0.754
- 0.759
- 0.875
- 0.868
- 0.692
- 0.969
- 0.65
- 0.576
- 0.761
- 0.344
- 0.603
- 0.838
- 0.669
- 0.619
- 0.946
- 0.607
- 0.611
- 0.814
- 0.663
- 0.664
- 0.046
- 0.44
- 0.836
- 0.885
- 0.534
- 0.838
- 0.911
- 0.869
- 0.647
- 0.871
- 0.38
- 0.447
- 0.757
- 0.7
- 0.812
- 0.677
- 0.739
- 0.914
- 0.894
- 0.957
- 0.873
- 0.96
- 0.68
- 0.45
- 0.91
- 0.441
- 0.862
- 0.383
- 0.511
- 0.875
- 0.942
- 0.963
- 0.65
- 0.925
- 0.26
- 0.27
- 0.838
- 0.45
- 0.927
- 0.879
- 0.46
train_loss:
- 1.184
- 0.976
- 0.633
- 0.54
- 0.539
- 0.552
- 0.44
- 0.521
- 0.452
- 0.425
- 0.496
- 0.468
- 0.451
- 0.393
- 0.473
- 0.398
- 0.405
- 0.463
- 0.437
- 0.443
- 0.431
- 0.434
- 0.434
- 0.36
- 0.356
- 0.383
- 0.376
- 0.377
- 0.385
- 0.436
- 0.325
- 0.397
- 0.365
- 0.341
- 0.434
- 0.428
- 0.26
- 0.381
- 0.397
- 0.337
- 0.409
- 0.374
- 0.44
- 0.327
- 0.38
- 0.406
- 0.341
- 0.33
- 0.365
- 0.415
- 0.365
- 0.329
- 0.361
- 0.376
- 0.311
- 0.483
- 0.327
- 0.346
- 0.314
- 0.266
- 0.332
- 0.385
- 0.394
- 0.406
- 0.379
- 0.327
- 0.292
- 0.371
- 0.312
- 0.311
- 0.257
- 0.347
- 0.309
- 0.392
- 0.33
- 0.342
- 0.341
- 0.323
- 0.295
- 0.388
- 0.341
- 0.345
- 0.288
- 0.31
- 0.319
- 0.313
- 0.344
- 0.404
- 0.339
- 0.332
- 0.351
- 0.313
- 0.327
- 0.366
- 0.324
- 0.326
- 0.318
- 0.359
- 0.321
- 0.382
unequal: 1
verbose: 1
