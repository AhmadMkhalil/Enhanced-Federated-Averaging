avg_train_accuracy: 0.322
avg_train_loss: 0.003
avg_type: avg
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.12654255319148935
- 0.23425531914893616
- 0.29840425531914894
- 0.37053191489361703
- 0.38595744680851063
- 0.4820212765957447
- 0.46664893617021275
- 0.5675531914893617
- 0.48579787234042554
- 0.45861702127659576
- 0.5351063829787234
- 0.5881382978723404
- 0.5550531914893617
- 0.5798404255319148
- 0.6024468085106383
- 0.6304787234042554
- 0.5894680851063829
- 0.5527659574468086
- 0.5867021276595744
- 0.5478723404255319
- 0.5831914893617022
- 0.6026595744680852
- 0.6162765957446809
- 0.5797872340425532
- 0.5628191489361702
- 0.655
- 0.6395744680851064
- 0.6326063829787234
- 0.626968085106383
- 0.6272872340425532
- 0.6117021276595744
- 0.6231914893617021
- 0.6666489361702128
- 0.6717553191489362
- 0.6260106382978723
- 0.6507978723404255
- 0.6046808510638297
- 0.6557446808510639
- 0.6749468085106383
- 0.6242553191489362
- 0.6821808510638298
- 0.6586702127659575
- 0.6778723404255319
- 0.637340425531915
- 0.6647340425531915
- 0.6115425531914893
- 0.6234042553191489
- 0.5938829787234042
- 0.6569148936170213
- 0.6590425531914894
- 0.6082446808510639
- 0.6748936170212766
- 0.683031914893617
- 0.6621808510638297
- 0.6458510638297872
- 0.6323404255319149
- 0.6101595744680851
- 0.6476063829787234
- 0.6873936170212765
- 0.6700531914893617
- 0.6825531914893617
- 0.6543617021276595
- 0.6867553191489362
- 0.6512234042553191
- 0.6994148936170212
- 0.6977127659574468
- 0.7018085106382979
- 0.6584042553191489
- 0.6622340425531915
- 0.6552127659574468
- 0.6952127659574469
- 0.6358510638297873
- 0.6610106382978723
- 0.6557978723404255
- 0.690531914893617
- 0.6857978723404256
- 0.6743617021276596
- 0.6729787234042554
- 0.6581382978723405
- 0.6916489361702127
- 0.6820744680851064
- 0.6328723404255319
- 0.6854787234042553
- 0.6785638297872341
- 0.6362234042553192
- 0.6933510638297873
- 0.6878723404255319
- 0.6667021276595745
- 0.699627659574468
- 0.7007978723404256
- 0.6606382978723404
- 0.6623404255319149
- 0.7075
- 0.7098404255319148
- 0.7081382978723404
- 0.6517021276595745
- 0.6594148936170213
- 0.6908510638297872
- 0.6734042553191489
- 0.6143617021276596
test_loss_list:
- 536.3213002681732
- 465.6963586807251
- 398.5315959453583
- 340.24247324466705
- 330.0228250026703
- 285.97228944301605
- 280.13594460487366
- 214.03265595436096
- 247.70047879219055
- 249.0159479379654
- 213.37863063812256
- 185.52521073818207
- 201.88883197307587
- 191.37871634960175
- 191.7891482114792
- 177.6142217516899
- 183.90529191493988
- 193.79697287082672
- 181.67991316318512
- 198.5422604084015
- 178.37306052446365
- 186.22309774160385
- 173.62519884109497
- 188.06794780492783
- 199.0239589214325
- 156.9744737148285
- 154.02388578653336
- 151.4892305135727
- 167.528094291687
- 166.09404796361923
- 173.6857985854149
- 164.4392449259758
- 144.62396240234375
- 136.94990515708923
- 161.00902253389359
- 158.8824604153633
- 174.12928175926208
- 152.48482471704483
- 142.5675027370453
- 163.3099518418312
- 136.7671553492546
- 144.917833507061
- 141.35643923282623
- 154.82281231880188
- 143.6485869884491
- 174.49758923053741
- 162.99372279644012
- 188.4903193116188
- 139.99082285165787
- 145.11826646327972
- 186.07650762796402
- 151.38385826349258
- 135.98069834709167
- 143.58950555324554
- 150.2068828344345
- 144.4823477268219
- 153.9249701499939
- 149.34489500522614
- 137.17990273237228
- 148.03844338655472
- 133.1540571451187
- 149.19590765237808
- 157.86841237545013
- 164.1338051557541
- 141.28162944316864
- 120.71663588285446
- 120.19678312540054
- 137.37418669462204
- 134.04923909902573
- 147.14711368083954
- 127.19793766736984
- 151.30748915672302
- 141.12718844413757
- 133.89548081159592
- 129.99123764038086
- 135.77987706661224
- 140.88456338644028
- 141.51669096946716
- 148.59317636489868
- 142.80920553207397
- 133.10690093040466
- 156.69852775335312
- 130.89352977275848
- 151.64926832914352
- 147.2816972732544
- 130.92092728614807
- 133.9038565158844
- 139.48873168230057
- 123.22752964496613
- 128.7691655755043
- 142.79327827692032
- 138.20905196666718
- 120.32072842121124
- 124.38933163881302
- 129.72419798374176
- 140.40423691272736
- 136.28645080327988
- 121.64758425951004
- 149.11091589927673
- 159.62510603666306
train_accuracy:
- 0.091
- 0.159
- 0.014
- 0.264
- 0.557
- 0.567
- 0.459
- 0.662
- 0.553
- 0.332
- 1.0
- 0.79
- 0.645
- 0.825
- 0.389
- 0.868
- 0.881
- 0.938
- 0.336
- 0.908
- 0.859
- 0.496
- 0.668
- 0.888
- 0.536
- 0.45
- 0.641
- 0.785
- 0.42
- 0.737
- 0.435
- 0.823
- 0.924
- 0.627
- 0.57
- 0.64
- 0.521
- 0.37
- 0.672
- 0.419
- 0.938
- 0.846
- 0.791
- 0.659
- 0.875
- 0.609
- 0.586
- 0.489
- 0.963
- 0.771
- 0.581
- 0.814
- 0.589
- 0.521
- 0.012
- 0.83
- 0.668
- 0.357
- 0.85
- 0.654
- 0.769
- 0.743
- 0.75
- 0.917
- 0.925
- 0.577
- 0.668
- 0.514
- 0.488
- 0.606
- 0.472
- 0.875
- 0.967
- 0.378
- 0.821
- 0.627
- 0.466
- 0.737
- 0.363
- 0.5
- 0.879
- 0.559
- 0.854
- 0.538
- 0.792
- 0.0
- 0.95
- 0.835
- 0.893
- 0.55
- 0.3
- 0.173
- 0.596
- 0.721
- 0.716
- 0.578
- 0.705
- 0.92
- 0.369
- 0.322
train_loss:
- 1.171
- 0.875
- 0.728
- 0.632
- 0.589
- 0.486
- 0.485
- 0.405
- 0.459
- 0.449
- 0.436
- 0.361
- 0.465
- 0.442
- 0.389
- 0.478
- 0.419
- 0.386
- 0.386
- 0.409
- 0.416
- 0.378
- 0.403
- 0.354
- 0.338
- 0.458
- 0.311
- 0.373
- 0.377
- 0.374
- 0.39
- 0.415
- 0.416
- 0.318
- 0.404
- 0.306
- 0.334
- 0.354
- 0.455
- 0.38
- 0.387
- 0.414
- 0.441
- 0.334
- 0.374
- 0.335
- 0.352
- 0.378
- 0.383
- 0.364
- 0.293
- 0.326
- 0.295
- 0.371
- 0.4
- 0.328
- 0.36
- 0.277
- 0.341
- 0.367
- 0.359
- 0.312
- 0.378
- 0.35
- 0.366
- 0.347
- 0.406
- 0.411
- 0.364
- 0.348
- 0.364
- 0.313
- 0.319
- 0.317
- 0.374
- 0.37
- 0.298
- 0.296
- 0.322
- 0.341
- 0.275
- 0.386
- 0.351
- 0.361
- 0.363
- 0.275
- 0.313
- 0.416
- 0.322
- 0.316
- 0.304
- 0.33
- 0.36
- 0.36
- 0.356
- 0.353
- 0.326
- 0.344
- 0.345
- 0.339
unequal: 1
verbose: 1
