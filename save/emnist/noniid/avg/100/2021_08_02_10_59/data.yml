avg_train_accuracy: 0.8
avg_train_loss: 0.003
avg_type: avg
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.15404255319148935
- 0.261968085106383
- 0.24898936170212765
- 0.3642021276595745
- 0.4436702127659575
- 0.45643617021276595
- 0.5148936170212766
- 0.5047340425531915
- 0.5212234042553191
- 0.5270212765957447
- 0.5088297872340426
- 0.5371276595744681
- 0.6314893617021277
- 0.5925
- 0.5751595744680851
- 0.5523404255319149
- 0.6047340425531915
- 0.6362765957446809
- 0.6198936170212765
- 0.6241489361702127
- 0.613031914893617
- 0.6216489361702128
- 0.6171808510638298
- 0.6556914893617021
- 0.6703191489361702
- 0.6826595744680851
- 0.6159042553191489
- 0.6863297872340426
- 0.6640425531914894
- 0.6861702127659575
- 0.6659574468085107
- 0.6626595744680851
- 0.6306914893617022
- 0.6351595744680851
- 0.634468085106383
- 0.6327127659574469
- 0.6207978723404255
- 0.625
- 0.6763297872340426
- 0.6371808510638298
- 0.7121808510638298
- 0.6531914893617021
- 0.6284574468085107
- 0.6486170212765957
- 0.6522872340425532
- 0.6536702127659575
- 0.638563829787234
- 0.6567021276595745
- 0.7071276595744681
- 0.7065957446808511
- 0.6556914893617021
- 0.6325531914893617
- 0.633031914893617
- 0.6536170212765957
- 0.6276063829787234
- 0.6706382978723404
- 0.6795744680851064
- 0.7152127659574468
- 0.7076595744680851
- 0.6709574468085107
- 0.7029255319148936
- 0.6967021276595745
- 0.6535106382978724
- 0.6890957446808511
- 0.6574468085106383
- 0.6486702127659575
- 0.6781382978723405
- 0.7042021276595745
- 0.666595744680851
- 0.6434042553191489
- 0.6426595744680851
- 0.6634042553191489
- 0.6562234042553191
- 0.6770212765957446
- 0.7192021276595745
- 0.6653191489361702
- 0.6955851063829788
- 0.6962234042553191
- 0.7153723404255319
- 0.7056914893617021
- 0.6808510638297872
- 0.6845744680851064
- 0.6925531914893617
- 0.683404255319149
- 0.6418617021276596
- 0.7046808510638298
- 0.7176063829787234
- 0.6874468085106383
- 0.6927659574468085
- 0.7263829787234043
- 0.7138297872340426
- 0.6787765957446809
- 0.6809574468085107
- 0.7063297872340426
- 0.7106914893617021
- 0.7138297872340426
- 0.701063829787234
- 0.6710106382978723
- 0.7085106382978723
- 0.6944148936170212
test_loss_list:
- 535.3828730583191
- 439.4699628353119
- 405.9609739780426
- 351.61811804771423
- 306.5188173055649
- 285.23185527324677
- 247.99486815929413
- 251.03727281093597
- 231.78080773353577
- 229.5482805967331
- 224.34395039081573
- 228.51779961585999
- 180.86454313993454
- 194.09771287441254
- 193.93508160114288
- 208.78079545497894
- 177.04383581876755
- 163.1953565478325
- 175.49257349967957
- 167.40125447511673
- 174.42446327209473
- 171.55087727308273
- 166.98450487852097
- 147.00538939237595
- 146.80278623104095
- 151.4124111533165
- 156.68583178520203
- 136.10731661319733
- 146.98263746500015
- 136.5103638768196
- 143.2797325849533
- 150.05871856212616
- 156.11640810966492
- 162.20883691310883
- 156.15248477458954
- 164.59766161441803
- 173.1891894340515
- 169.50025755167007
- 136.76542180776596
- 154.39551335573196
- 127.64293795824051
- 150.69106078147888
- 151.7021702528
- 141.70255154371262
- 159.6432607769966
- 157.45193272829056
- 149.32658910751343
- 142.73232823610306
- 126.79173237085342
- 128.3289183974266
- 147.46411114931107
- 161.88411968946457
- 154.87545502185822
- 138.96575611829758
- 154.7295644879341
- 136.7266165614128
- 133.4087194800377
- 125.22768408060074
- 126.04345458745956
- 149.93000310659409
- 133.94122678041458
- 130.41279393434525
- 146.48152685165405
- 133.39069575071335
- 139.76645934581757
- 150.9268417954445
- 129.17452561855316
- 123.97712105512619
- 134.7825996875763
- 137.83087503910065
- 147.21021032333374
- 136.28590494394302
- 140.94853603839874
- 130.1255163550377
- 133.29430747032166
- 136.83546650409698
- 124.7434749007225
- 137.89725542068481
- 123.87554502487183
- 120.229416847229
- 127.94595235586166
- 130.06201475858688
- 151.3588879108429
- 132.65709978342056
- 153.21327137947083
- 120.96199774742126
- 113.72288250923157
- 128.38662993907928
- 131.35788643360138
- 122.5668671131134
- 120.63765394687653
- 139.6278225183487
- 132.81958252191544
- 127.90945053100586
- 118.91853541135788
- 116.64785951375961
- 133.5674283504486
- 142.00407248735428
- 124.20514917373657
- 127.14889967441559
train_accuracy:
- 0.388
- 0.535
- 1.0
- 0.075
- 0.207
- 0.756
- 0.35
- 0.85
- 0.612
- 0.632
- 0.618
- 0.794
- 0.933
- 0.556
- 0.777
- 0.714
- 0.621
- 0.912
- 0.455
- 0.667
- 0.45
- 0.914
- 0.659
- 0.617
- 0.323
- 0.831
- 0.476
- 0.97
- 0.871
- 0.288
- 0.954
- 0.58
- 0.68
- 0.706
- 0.412
- 0.542
- 0.9
- 0.525
- 0.571
- 0.331
- 0.942
- 0.568
- 0.813
- 0.624
- 0.929
- 0.908
- 0.68
- 0.913
- 0.938
- 0.93
- 0.978
- 0.908
- 0.611
- 0.913
- 0.16
- 0.812
- 0.955
- 0.83
- 0.846
- 0.921
- 0.75
- 0.782
- 0.684
- 0.386
- 0.496
- 0.911
- 0.735
- 0.943
- 0.943
- 0.812
- 0.967
- 0.596
- 0.725
- 0.521
- 1.0
- 0.735
- 0.636
- 0.843
- 0.925
- 0.975
- 0.914
- 0.9
- 0.767
- 0.95
- 0.95
- 0.325
- 0.883
- 0.587
- 0.668
- 0.62
- 0.703
- 0.975
- 0.692
- 0.617
- 0.794
- 0.925
- 0.912
- 0.744
- 0.658
- 0.8
train_loss:
- 1.172
- 0.676
- 0.626
- 0.507
- 0.487
- 0.54
- 0.351
- 0.485
- 0.418
- 0.424
- 0.436
- 0.48
- 0.503
- 0.457
- 0.401
- 0.376
- 0.361
- 0.407
- 0.432
- 0.365
- 0.477
- 0.462
- 0.416
- 0.306
- 0.411
- 0.328
- 0.378
- 0.432
- 0.354
- 0.348
- 0.401
- 0.406
- 0.404
- 0.412
- 0.417
- 0.344
- 0.325
- 0.299
- 0.368
- 0.357
- 0.399
- 0.349
- 0.408
- 0.375
- 0.287
- 0.317
- 0.362
- 0.376
- 0.297
- 0.281
- 0.343
- 0.327
- 0.357
- 0.294
- 0.335
- 0.355
- 0.299
- 0.337
- 0.359
- 0.283
- 0.318
- 0.368
- 0.332
- 0.316
- 0.275
- 0.379
- 0.327
- 0.334
- 0.331
- 0.337
- 0.416
- 0.295
- 0.285
- 0.317
- 0.338
- 0.317
- 0.367
- 0.338
- 0.292
- 0.355
- 0.307
- 0.357
- 0.22
- 0.327
- 0.342
- 0.313
- 0.35
- 0.271
- 0.327
- 0.253
- 0.318
- 0.307
- 0.213
- 0.339
- 0.389
- 0.257
- 0.298
- 0.35
- 0.327
- 0.31
unequal: 1
verbose: 1
