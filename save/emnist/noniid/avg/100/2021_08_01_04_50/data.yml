avg_train_accuracy: 0.39
avg_train_loss: 0.003
avg_type: avg
dataset: emnist
epochs: 100
frac: 0.1
iid: 0
kernel_num: 9
kernel_sizes: 3,4,5
local_bs: 10
local_ep: 10
lr: 0.01
max_pool: 'True'
model: cnn
momentum: 0.5
norm: batch_norm
num_channels: 1
num_classes: 47
num_filters: 32
num_users: 100
optimizer: sgd
seed: 1
test_accuracy_list:
- 0.12170212765957447
- 0.27372340425531916
- 0.3372872340425532
- 0.4186170212765957
- 0.46154255319148935
- 0.466968085106383
- 0.44196808510638297
- 0.5292553191489362
- 0.5455851063829787
- 0.5215425531914893
- 0.4982446808510638
- 0.5289893617021276
- 0.5321808510638298
- 0.558404255319149
- 0.5118085106382979
- 0.535372340425532
- 0.5853191489361702
- 0.5851595744680851
- 0.6345744680851064
- 0.6338297872340426
- 0.5458510638297872
- 0.6236170212765958
- 0.614468085106383
- 0.5806914893617021
- 0.6490957446808511
- 0.6209574468085106
- 0.6586170212765957
- 0.6208510638297873
- 0.6025
- 0.6242021276595745
- 0.6277127659574468
- 0.6595744680851063
- 0.6344148936170213
- 0.6375531914893617
- 0.6190425531914894
- 0.6288297872340426
- 0.6576063829787234
- 0.6778191489361702
- 0.6666489361702128
- 0.6390425531914894
- 0.6579787234042553
- 0.6560106382978723
- 0.6592021276595744
- 0.7060106382978724
- 0.6861702127659575
- 0.6189893617021277
- 0.6931914893617022
- 0.6822340425531915
- 0.6416489361702128
- 0.6815425531914894
- 0.6623936170212766
- 0.6514893617021277
- 0.6057446808510638
- 0.6688297872340425
- 0.655904255319149
- 0.6901063829787234
- 0.650904255319149
- 0.6655319148936171
- 0.7079787234042553
- 0.6846276595744681
- 0.6390425531914894
- 0.7015425531914894
- 0.7005851063829788
- 0.6813829787234043
- 0.694468085106383
- 0.7176063829787234
- 0.6975
- 0.6460638297872341
- 0.6220212765957447
- 0.6799468085106383
- 0.6677127659574468
- 0.6556914893617021
- 0.6619148936170213
- 0.6686702127659574
- 0.6858510638297872
- 0.655904255319149
- 0.6914361702127659
- 0.6986170212765958
- 0.6761170212765958
- 0.689468085106383
- 0.6652127659574468
- 0.6346808510638298
- 0.683031914893617
- 0.6842553191489362
- 0.6533510638297872
- 0.6540957446808511
- 0.6988297872340425
- 0.6739893617021276
- 0.7018085106382979
- 0.7151595744680851
- 0.6532446808510638
- 0.6224468085106383
- 0.6736170212765957
- 0.7124468085106384
- 0.6582978723404256
- 0.6860106382978723
- 0.6775
- 0.6706914893617021
- 0.654468085106383
- 0.6193085106382978
test_loss_list:
- 538.801703453064
- 445.945440530777
- 377.7377083301544
- 329.2996315956116
- 292.95016264915466
- 270.6994812488556
- 258.79290199279785
- 232.9757993221283
- 207.707146525383
- 235.1634681224823
- 234.15228879451752
- 208.4116908311844
- 217.04947912693024
- 194.77904748916626
- 212.12711477279663
- 208.4377360343933
- 196.43749046325684
- 185.75564193725586
- 165.7725304365158
- 174.10841381549835
- 208.57003390789032
- 174.3982309103012
- 157.79332399368286
- 181.9266517162323
- 157.90762448310852
- 164.6226813197136
- 158.74926948547363
- 174.2961447238922
- 174.8378285765648
- 158.39132714271545
- 167.43025696277618
- 155.59777384996414
- 164.95308262109756
- 158.7819190621376
- 170.884226500988
- 161.67215114831924
- 159.80952936410904
- 138.50343823432922
- 142.37558966875076
- 165.78240489959717
- 145.99895185232162
- 142.98170602321625
- 148.16171646118164
- 132.4561344385147
- 133.59308236837387
- 154.74332094192505
- 138.2828009724617
- 150.48399674892426
- 157.68028271198273
- 143.31244879961014
- 148.06351798772812
- 149.10914087295532
- 166.16414469480515
- 149.32199376821518
- 153.0450777411461
- 127.56335842609406
- 140.37547481060028
- 140.33698439598083
- 125.29161471128464
- 136.98692506551743
- 156.73571836948395
- 132.2396804690361
- 122.31540888547897
- 132.5499193072319
- 131.11584740877151
- 121.29995810985565
- 129.53767293691635
- 142.4558811187744
- 153.0966433286667
- 141.3440552353859
- 137.01081079244614
- 147.735198199749
- 141.30895495414734
- 135.51446956396103
- 131.73978769779205
- 145.87212598323822
- 125.53952932357788
- 128.49436110258102
- 137.90988546609879
- 125.36937135457993
- 132.63323265314102
- 140.41487389802933
- 133.90263783931732
- 137.06208789348602
- 145.45499521493912
- 146.49046647548676
- 132.88390052318573
- 132.2180414199829
- 125.93237382173538
- 126.33421850204468
- 141.90346837043762
- 164.6320618391037
- 138.7861351966858
- 124.0620521903038
- 135.96223479509354
- 128.56895101070404
- 141.38107758760452
- 134.46461188793182
- 147.2290768623352
- 158.39375567436218
train_accuracy:
- 0.238
- 0.205
- 0.71
- 0.204
- 0.695
- 0.906
- 0.59
- 0.29
- 0.167
- 0.893
- 0.411
- 0.558
- 0.467
- 0.925
- 0.45
- 0.342
- 1.0
- 0.359
- 0.714
- 0.85
- 0.311
- 0.786
- 0.562
- 0.153
- 0.862
- 0.96
- 0.429
- 0.79
- 0.641
- 0.575
- 0.671
- 0.893
- 0.829
- 0.933
- 0.325
- 0.776
- 0.778
- 0.646
- 0.8
- 0.925
- 0.559
- 0.633
- 0.277
- 0.925
- 0.772
- 0.612
- 0.878
- 0.908
- 0.6
- 0.827
- 0.819
- 0.421
- 0.493
- 0.923
- 0.307
- 0.857
- 0.118
- 0.962
- 0.404
- 0.771
- 0.627
- 0.611
- 0.615
- 0.9
- 0.397
- 0.85
- 0.763
- 0.675
- 0.567
- 0.777
- 0.67
- 0.511
- 0.707
- 0.81
- 0.413
- 0.767
- 0.956
- 0.879
- 0.521
- 0.775
- 0.64
- 0.97
- 0.867
- 0.886
- 0.567
- 0.43
- 0.759
- 0.778
- 0.644
- 0.686
- 0.737
- 0.54
- 0.95
- 0.967
- 0.681
- 0.681
- 0.811
- 0.842
- 0.9
- 0.39
train_loss:
- 1.033
- 0.816
- 0.722
- 0.685
- 0.587
- 0.464
- 0.52
- 0.473
- 0.458
- 0.507
- 0.484
- 0.486
- 0.443
- 0.484
- 0.426
- 0.479
- 0.363
- 0.423
- 0.368
- 0.434
- 0.377
- 0.428
- 0.363
- 0.421
- 0.478
- 0.434
- 0.381
- 0.38
- 0.356
- 0.367
- 0.382
- 0.379
- 0.417
- 0.362
- 0.331
- 0.32
- 0.352
- 0.478
- 0.359
- 0.363
- 0.339
- 0.301
- 0.356
- 0.317
- 0.397
- 0.429
- 0.347
- 0.392
- 0.34
- 0.321
- 0.435
- 0.451
- 0.385
- 0.333
- 0.348
- 0.375
- 0.41
- 0.359
- 0.323
- 0.362
- 0.404
- 0.293
- 0.312
- 0.382
- 0.391
- 0.275
- 0.308
- 0.276
- 0.36
- 0.262
- 0.347
- 0.366
- 0.387
- 0.322
- 0.314
- 0.45
- 0.315
- 0.356
- 0.324
- 0.316
- 0.401
- 0.376
- 0.375
- 0.306
- 0.316
- 0.322
- 0.281
- 0.408
- 0.324
- 0.322
- 0.375
- 0.389
- 0.321
- 0.309
- 0.332
- 0.242
- 0.28
- 0.329
- 0.342
- 0.35
unequal: 1
verbose: 1
